{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6513d6a",
   "metadata": {},
   "source": [
    "# HuggingFace Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa1a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global imports\n",
    "from probe_gen.paths import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ed885",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run to set environment variables if want to\n",
    "# %env HF_TOKEN="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee62a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ac293a355c49c4b3736be44506bcc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "jailbreaks/ministral_8b_on_policy_train.(…):   0%|          | 0.00/29.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to: /workspace/LASR-probe-gen/data/refusal/jailbreaks/ministral_8b_on_policy_train.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Run to download jsonl files from hugging face if want to\n",
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "behavior = \"refusal\"\n",
    "datasource = \"rlhf\"\n",
    "repo_id = f\"lasrprobegen/{behavior}-activations\"\n",
    "files_to_download = [\n",
    "    \"llama_3b_incentivised_test.jsonl\",\n",
    "    \"llama_3b_incentivised_train.jsonl\", \n",
    "    \"llama_3b_on_policy_test.jsonl\", \n",
    "    \"llama_3b_on_policy_train.jsonl\", \n",
    "    \"llama_3b_prompted_test.jsonl\", \n",
    "    \"llama_3b_prompted_train.jsonl\", \n",
    "    \"llama_3b_prompted_test.jsonl\", \n",
    "    # \"qwen_3b_on_policy_train.jsonl\", \n",
    "    # \"qwen_3b_on_policy_test.jsonl\", \n",
    "    \"ministral_8b_on_policy_train.jsonl\", \n",
    "    \"ministral_8b_on_policy_test.jsonl\", \n",
    "    # \"qwen_7b_on_policy_train.jsonl\", \n",
    "    # \"qwen_7b_on_policy_test.jsonl\", \n",
    "]\n",
    "local_dir = str(data.data / behavior)\n",
    "os.makedirs(local_dir, exist_ok=True)\n",
    "for filename in files_to_download:\n",
    "    file_path = hf_hub_download(\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"dataset\",\n",
    "        filename=datasource + \"/\" + filename,\n",
    "        local_dir=local_dir,\n",
    "        token=os.environ.get(\"HF_TOKEN\")\n",
    "    )\n",
    "    print(f\"Downloaded to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8664acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for replacing names with other names in a hugging face repo\n",
    "from huggingface_hub import HfApi, list_repo_files, CommitOperationCopy, CommitOperationDelete\n",
    "\n",
    "def rename_files_in_hf_dataset(repo_id, old_pattern, new_pattern, repo_type=\"dataset\", confirm=True):\n",
    "    api = HfApi()\n",
    "    \n",
    "    try:\n",
    "        files = list_repo_files(repo_id=repo_id, repo_type=repo_type)\n",
    "        files_to_rename = [f for f in files if old_pattern in f]\n",
    "        \n",
    "        if not files_to_rename:\n",
    "            return False\n",
    "        \n",
    "        if confirm:\n",
    "            print(f\"Found {len(files_to_rename)} files to rename:\")\n",
    "            for file in files_to_rename:\n",
    "                new_name = file.replace(old_pattern, new_pattern)\n",
    "                print(f\"  - {file} -> {new_name}\")\n",
    "            \n",
    "            response = input(f\"\\nProceed with renaming {len(files_to_rename)} files? (y/N): \")\n",
    "            if response.lower() != 'y':\n",
    "                return False\n",
    "        \n",
    "        operations = []\n",
    "        \n",
    "        for old_filename in files_to_rename:\n",
    "            new_filename = old_filename.replace(old_pattern, new_pattern)\n",
    "            \n",
    "            operations.append(\n",
    "                CommitOperationCopy(\n",
    "                    src_path_in_repo=old_filename,\n",
    "                    path_in_repo=new_filename\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            operations.append(\n",
    "                CommitOperationDelete(path_in_repo=old_filename)\n",
    "            )\n",
    "        \n",
    "        commit_info = api.create_commit(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type,\n",
    "            operations=operations,\n",
    "            commit_message=f\"Rename {len(files_to_rename)} files: replace '{old_pattern}' with '{new_pattern}'\"\n",
    "        )\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f195854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, list_repo_files, CommitOperationCopy, CommitOperationDelete\n",
    "\n",
    "# Initialize the API\n",
    "api = HfApi()\n",
    "\n",
    "def move_all_to_folder(\n",
    "    target_folder: str,\n",
    "    repo_id: str,\n",
    "    confirm: bool = True,\n",
    "    match: str | None = None,\n",
    "    source_folder: str = \"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Move files from a Hugging Face repo into a subfolder, optionally filtering.\n",
    "\n",
    "    Args:\n",
    "        target_folder (str): The new folder (created inside source_folder).\n",
    "        repo_id (str): The Hugging Face repo ID.\n",
    "        confirm (bool): Whether to ask for confirmation before committing.\n",
    "        match (str | None): If provided, only move files whose names contain this substring.\n",
    "        source_folder (str): Only consider files directly inside this folder (non-recursive).\n",
    "                             \"\" means repo root.\n",
    "    \"\"\"\n",
    "    repo_type = \"dataset\"\n",
    "    if source_folder and not source_folder.endswith(\"/\"):\n",
    "        source_folder += \"/\"\n",
    "    if target_folder and not target_folder.endswith(\"/\"):\n",
    "        target_folder += \"/\"\n",
    "\n",
    "    files = list_repo_files(repo_id=repo_id, repo_type=repo_type)\n",
    "\n",
    "    # Restrict to immediate files inside source_folder (non-recursive)\n",
    "    files_to_move = [\n",
    "        f for f in files\n",
    "        if f.startswith(source_folder) and \"/\" not in f[len(source_folder):]\n",
    "    ]\n",
    "\n",
    "    # Filter by match string if provided\n",
    "    if match is not None:\n",
    "        files_to_move = [f for f in files_to_move if match in f]\n",
    "\n",
    "    if not files_to_move:\n",
    "        print(f\"No files to move (source='{source_folder}', match='{match}', target='{target_folder}').\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(files_to_move)} files to move:\")\n",
    "    for old_filename in files_to_move:\n",
    "        # Insert target folder *inside* source_folder\n",
    "        new_filename = f\"{source_folder}{target_folder}{old_filename[len(source_folder):]}\"\n",
    "        print(f\"  - {old_filename} -> {new_filename}\")\n",
    "\n",
    "    if confirm:\n",
    "        response = input(f\"\\nProceed with moving {len(files_to_move)} files into '{source_folder}{target_folder}'? (y/N): \")\n",
    "        if response.lower() != \"y\":\n",
    "            print(\"Operation cancelled.\")\n",
    "            return\n",
    "\n",
    "    operations = []\n",
    "    for old_filename in files_to_move:\n",
    "        new_filename = f\"{source_folder}{target_folder}{old_filename[len(source_folder):]}\"\n",
    "        operations.append(CommitOperationCopy(src_path_in_repo=old_filename, path_in_repo=new_filename))\n",
    "        operations.append(CommitOperationDelete(path_in_repo=old_filename))\n",
    "\n",
    "    commit_info = api.create_commit(\n",
    "        repo_id=repo_id,\n",
    "        repo_type=repo_type,\n",
    "        operations=operations,\n",
    "        commit_message=f\"Move {len(files_to_move)} files from '{source_folder}' into '{source_folder}{target_folder}'\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✓ Successfully moved {len(files_to_move)} files into '{source_folder}{target_folder}'!\")\n",
    "    print(f\"Commit: {commit_info.commit_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5b58c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 files to move:\n",
      "  - llama_3b_story_balanced_1k.jsonl -> tinystories/llama_3b_story_balanced_1k.jsonl\n",
      "  - llama_3b_story_balanced_1k_layer_0.pkl -> tinystories/llama_3b_story_balanced_1k_layer_0.pkl\n",
      "  - llama_3b_story_balanced_1k_layer_12.pkl -> tinystories/llama_3b_story_balanced_1k_layer_12.pkl\n",
      "  - llama_3b_story_balanced_1k_layer_15.pkl -> tinystories/llama_3b_story_balanced_1k_layer_15.pkl\n",
      "  - llama_3b_story_balanced_1k_layer_18.pkl -> tinystories/llama_3b_story_balanced_1k_layer_18.pkl\n",
      "  - llama_3b_story_balanced_1k_layer_21.pkl -> tinystories/llama_3b_story_balanced_1k_layer_21.pkl\n",
      "  - llama_3b_story_balanced_1k_layer_24.pkl -> tinystories/llama_3b_story_balanced_1k_layer_24.pkl\n",
      "  - llama_3b_story_balanced_1k_layer_27.pkl -> tinystories/llama_3b_story_balanced_1k_layer_27.pkl\n",
      "  - llama_3b_story_balanced_1k_layer_3.pkl -> tinystories/llama_3b_story_balanced_1k_layer_3.pkl\n",
      "  - llama_3b_story_balanced_1k_layer_6.pkl -> tinystories/llama_3b_story_balanced_1k_layer_6.pkl\n",
      "  - llama_3b_story_balanced_1k_layer_9.pkl -> tinystories/llama_3b_story_balanced_1k_layer_9.pkl\n",
      "  - llama_3b_story_balanced_5k.jsonl -> tinystories/llama_3b_story_balanced_5k.jsonl\n",
      "  - llama_3b_story_balanced_5k_layer_0.pkl -> tinystories/llama_3b_story_balanced_5k_layer_0.pkl\n",
      "  - llama_3b_story_balanced_5k_layer_12.pkl -> tinystories/llama_3b_story_balanced_5k_layer_12.pkl\n",
      "  - llama_3b_story_balanced_5k_layer_15.pkl -> tinystories/llama_3b_story_balanced_5k_layer_15.pkl\n",
      "  - llama_3b_story_balanced_5k_layer_18.pkl -> tinystories/llama_3b_story_balanced_5k_layer_18.pkl\n",
      "  - llama_3b_story_balanced_5k_layer_21.pkl -> tinystories/llama_3b_story_balanced_5k_layer_21.pkl\n",
      "  - llama_3b_story_balanced_5k_layer_24.pkl -> tinystories/llama_3b_story_balanced_5k_layer_24.pkl\n",
      "  - llama_3b_story_balanced_5k_layer_27.pkl -> tinystories/llama_3b_story_balanced_5k_layer_27.pkl\n",
      "  - llama_3b_story_balanced_5k_layer_3.pkl -> tinystories/llama_3b_story_balanced_5k_layer_3.pkl\n",
      "  - llama_3b_story_balanced_5k_layer_6.pkl -> tinystories/llama_3b_story_balanced_5k_layer_6.pkl\n",
      "  - llama_3b_story_balanced_5k_layer_9.pkl -> tinystories/llama_3b_story_balanced_5k_layer_9.pkl\n",
      "\n",
      "✓ Successfully moved 22 files into 'tinystories/'!\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/lists-activations/commit/6869881f00cad35dde7b4137a0706067f2cdf62a\n",
      "Found 22 files to rename:\n",
      "  - tinystories/llama_3b_story_balanced_1k.jsonl -> tinystories/llama_3b_balanced_1k.jsonl\n",
      "  - tinystories/llama_3b_story_balanced_1k_layer_0.pkl -> tinystories/llama_3b_balanced_1k_layer_0.pkl\n",
      "  - tinystories/llama_3b_story_balanced_1k_layer_12.pkl -> tinystories/llama_3b_balanced_1k_layer_12.pkl\n",
      "  - tinystories/llama_3b_story_balanced_1k_layer_15.pkl -> tinystories/llama_3b_balanced_1k_layer_15.pkl\n",
      "  - tinystories/llama_3b_story_balanced_1k_layer_18.pkl -> tinystories/llama_3b_balanced_1k_layer_18.pkl\n",
      "  - tinystories/llama_3b_story_balanced_1k_layer_21.pkl -> tinystories/llama_3b_balanced_1k_layer_21.pkl\n",
      "  - tinystories/llama_3b_story_balanced_1k_layer_24.pkl -> tinystories/llama_3b_balanced_1k_layer_24.pkl\n",
      "  - tinystories/llama_3b_story_balanced_1k_layer_27.pkl -> tinystories/llama_3b_balanced_1k_layer_27.pkl\n",
      "  - tinystories/llama_3b_story_balanced_1k_layer_3.pkl -> tinystories/llama_3b_balanced_1k_layer_3.pkl\n",
      "  - tinystories/llama_3b_story_balanced_1k_layer_6.pkl -> tinystories/llama_3b_balanced_1k_layer_6.pkl\n",
      "  - tinystories/llama_3b_story_balanced_1k_layer_9.pkl -> tinystories/llama_3b_balanced_1k_layer_9.pkl\n",
      "  - tinystories/llama_3b_story_balanced_5k.jsonl -> tinystories/llama_3b_balanced_5k.jsonl\n",
      "  - tinystories/llama_3b_story_balanced_5k_layer_0.pkl -> tinystories/llama_3b_balanced_5k_layer_0.pkl\n",
      "  - tinystories/llama_3b_story_balanced_5k_layer_12.pkl -> tinystories/llama_3b_balanced_5k_layer_12.pkl\n",
      "  - tinystories/llama_3b_story_balanced_5k_layer_15.pkl -> tinystories/llama_3b_balanced_5k_layer_15.pkl\n",
      "  - tinystories/llama_3b_story_balanced_5k_layer_18.pkl -> tinystories/llama_3b_balanced_5k_layer_18.pkl\n",
      "  - tinystories/llama_3b_story_balanced_5k_layer_21.pkl -> tinystories/llama_3b_balanced_5k_layer_21.pkl\n",
      "  - tinystories/llama_3b_story_balanced_5k_layer_24.pkl -> tinystories/llama_3b_balanced_5k_layer_24.pkl\n",
      "  - tinystories/llama_3b_story_balanced_5k_layer_27.pkl -> tinystories/llama_3b_balanced_5k_layer_27.pkl\n",
      "  - tinystories/llama_3b_story_balanced_5k_layer_3.pkl -> tinystories/llama_3b_balanced_5k_layer_3.pkl\n",
      "  - tinystories/llama_3b_story_balanced_5k_layer_6.pkl -> tinystories/llama_3b_balanced_5k_layer_6.pkl\n",
      "  - tinystories/llama_3b_story_balanced_5k_layer_9.pkl -> tinystories/llama_3b_balanced_5k_layer_9.pkl\n",
      "Found 20 files to move:\n",
      "  - tinystories/llama_3b_balanced_1k_layer_0.pkl -> tinystories/llama_3b/llama_3b_balanced_1k_layer_0.pkl\n",
      "  - tinystories/llama_3b_balanced_1k_layer_12.pkl -> tinystories/llama_3b/llama_3b_balanced_1k_layer_12.pkl\n",
      "  - tinystories/llama_3b_balanced_1k_layer_15.pkl -> tinystories/llama_3b/llama_3b_balanced_1k_layer_15.pkl\n",
      "  - tinystories/llama_3b_balanced_1k_layer_18.pkl -> tinystories/llama_3b/llama_3b_balanced_1k_layer_18.pkl\n",
      "  - tinystories/llama_3b_balanced_1k_layer_21.pkl -> tinystories/llama_3b/llama_3b_balanced_1k_layer_21.pkl\n",
      "  - tinystories/llama_3b_balanced_1k_layer_24.pkl -> tinystories/llama_3b/llama_3b_balanced_1k_layer_24.pkl\n",
      "  - tinystories/llama_3b_balanced_1k_layer_27.pkl -> tinystories/llama_3b/llama_3b_balanced_1k_layer_27.pkl\n",
      "  - tinystories/llama_3b_balanced_1k_layer_3.pkl -> tinystories/llama_3b/llama_3b_balanced_1k_layer_3.pkl\n",
      "  - tinystories/llama_3b_balanced_1k_layer_6.pkl -> tinystories/llama_3b/llama_3b_balanced_1k_layer_6.pkl\n",
      "  - tinystories/llama_3b_balanced_1k_layer_9.pkl -> tinystories/llama_3b/llama_3b_balanced_1k_layer_9.pkl\n",
      "  - tinystories/llama_3b_balanced_5k_layer_0.pkl -> tinystories/llama_3b/llama_3b_balanced_5k_layer_0.pkl\n",
      "  - tinystories/llama_3b_balanced_5k_layer_12.pkl -> tinystories/llama_3b/llama_3b_balanced_5k_layer_12.pkl\n",
      "  - tinystories/llama_3b_balanced_5k_layer_15.pkl -> tinystories/llama_3b/llama_3b_balanced_5k_layer_15.pkl\n",
      "  - tinystories/llama_3b_balanced_5k_layer_18.pkl -> tinystories/llama_3b/llama_3b_balanced_5k_layer_18.pkl\n",
      "  - tinystories/llama_3b_balanced_5k_layer_21.pkl -> tinystories/llama_3b/llama_3b_balanced_5k_layer_21.pkl\n",
      "  - tinystories/llama_3b_balanced_5k_layer_24.pkl -> tinystories/llama_3b/llama_3b_balanced_5k_layer_24.pkl\n",
      "  - tinystories/llama_3b_balanced_5k_layer_27.pkl -> tinystories/llama_3b/llama_3b_balanced_5k_layer_27.pkl\n",
      "  - tinystories/llama_3b_balanced_5k_layer_3.pkl -> tinystories/llama_3b/llama_3b_balanced_5k_layer_3.pkl\n",
      "  - tinystories/llama_3b_balanced_5k_layer_6.pkl -> tinystories/llama_3b/llama_3b_balanced_5k_layer_6.pkl\n",
      "  - tinystories/llama_3b_balanced_5k_layer_9.pkl -> tinystories/llama_3b/llama_3b_balanced_5k_layer_9.pkl\n",
      "\n",
      "✓ Successfully moved 20 files into 'tinystories/llama_3b/'!\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/lists-activations/commit/b36ee08a79ab6ef45c7196fefb3ef431ec6926b5\n"
     ]
    }
   ],
   "source": [
    "move_all_to_folder(\"tinystories\", repo_id, match=\"story\")\n",
    "success = rename_files_in_hf_dataset(repo_id, \"_story\", \"\")\n",
    "move_all_to_folder(\"llama_3b\", repo_id, source_folder=\"tinystories\", match=\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e00b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 files to move:\n",
      "  - llama_3b_brazil_1k_balanced.jsonl -> brazilian/llama_3b_brazil_1k_balanced.jsonl\n",
      "  - llama_3b_brazil_1k_balanced_layer_0.pkl -> brazilian/llama_3b_brazil_1k_balanced_layer_0.pkl\n",
      "  - llama_3b_brazil_1k_balanced_layer_12.pkl -> brazilian/llama_3b_brazil_1k_balanced_layer_12.pkl\n",
      "  - llama_3b_brazil_1k_balanced_layer_15.pkl -> brazilian/llama_3b_brazil_1k_balanced_layer_15.pkl\n",
      "  - llama_3b_brazil_1k_balanced_layer_18.pkl -> brazilian/llama_3b_brazil_1k_balanced_layer_18.pkl\n",
      "  - llama_3b_brazil_1k_balanced_layer_21.pkl -> brazilian/llama_3b_brazil_1k_balanced_layer_21.pkl\n",
      "  - llama_3b_brazil_1k_balanced_layer_24.pkl -> brazilian/llama_3b_brazil_1k_balanced_layer_24.pkl\n",
      "  - llama_3b_brazil_1k_balanced_layer_27.pkl -> brazilian/llama_3b_brazil_1k_balanced_layer_27.pkl\n",
      "  - llama_3b_brazil_1k_balanced_layer_3.pkl -> brazilian/llama_3b_brazil_1k_balanced_layer_3.pkl\n",
      "  - llama_3b_brazil_1k_balanced_layer_6.pkl -> brazilian/llama_3b_brazil_1k_balanced_layer_6.pkl\n",
      "  - llama_3b_brazil_1k_balanced_layer_9.pkl -> brazilian/llama_3b_brazil_1k_balanced_layer_9.pkl\n",
      "  - llama_3b_brazil_prompted_balanced_1k.jsonl -> brazilian/llama_3b_brazil_prompted_balanced_1k.jsonl\n",
      "  - llama_3b_brazil_prompted_balanced_1k_layer_0.pkl -> brazilian/llama_3b_brazil_prompted_balanced_1k_layer_0.pkl\n",
      "  - llama_3b_brazil_prompted_balanced_1k_layer_12.pkl -> brazilian/llama_3b_brazil_prompted_balanced_1k_layer_12.pkl\n",
      "  - llama_3b_brazil_prompted_balanced_1k_layer_15.pkl -> brazilian/llama_3b_brazil_prompted_balanced_1k_layer_15.pkl\n",
      "  - llama_3b_brazil_prompted_balanced_1k_layer_18.pkl -> brazilian/llama_3b_brazil_prompted_balanced_1k_layer_18.pkl\n",
      "  - llama_3b_brazil_prompted_balanced_1k_layer_21.pkl -> brazilian/llama_3b_brazil_prompted_balanced_1k_layer_21.pkl\n",
      "  - llama_3b_brazil_prompted_balanced_1k_layer_24.pkl -> brazilian/llama_3b_brazil_prompted_balanced_1k_layer_24.pkl\n",
      "  - llama_3b_brazil_prompted_balanced_1k_layer_27.pkl -> brazilian/llama_3b_brazil_prompted_balanced_1k_layer_27.pkl\n",
      "  - llama_3b_brazil_prompted_balanced_1k_layer_3.pkl -> brazilian/llama_3b_brazil_prompted_balanced_1k_layer_3.pkl\n",
      "  - llama_3b_brazil_prompted_balanced_1k_layer_6.pkl -> brazilian/llama_3b_brazil_prompted_balanced_1k_layer_6.pkl\n",
      "  - llama_3b_brazil_prompted_balanced_1k_layer_9.pkl -> brazilian/llama_3b_brazil_prompted_balanced_1k_layer_9.pkl\n",
      "  - qwen_3b_brazil_1k_balanced.jsonl -> brazilian/qwen_3b_brazil_1k_balanced.jsonl\n",
      "  - qwen_3b_brazil_1k_balanced_layer_0.pkl -> brazilian/qwen_3b_brazil_1k_balanced_layer_0.pkl\n",
      "  - qwen_3b_brazil_1k_balanced_layer_12.pkl -> brazilian/qwen_3b_brazil_1k_balanced_layer_12.pkl\n",
      "  - qwen_3b_brazil_1k_balanced_layer_15.pkl -> brazilian/qwen_3b_brazil_1k_balanced_layer_15.pkl\n",
      "  - qwen_3b_brazil_1k_balanced_layer_18.pkl -> brazilian/qwen_3b_brazil_1k_balanced_layer_18.pkl\n",
      "  - qwen_3b_brazil_1k_balanced_layer_21.pkl -> brazilian/qwen_3b_brazil_1k_balanced_layer_21.pkl\n",
      "  - qwen_3b_brazil_1k_balanced_layer_24.pkl -> brazilian/qwen_3b_brazil_1k_balanced_layer_24.pkl\n",
      "  - qwen_3b_brazil_1k_balanced_layer_27.pkl -> brazilian/qwen_3b_brazil_1k_balanced_layer_27.pkl\n",
      "  - qwen_3b_brazil_1k_balanced_layer_3.pkl -> brazilian/qwen_3b_brazil_1k_balanced_layer_3.pkl\n",
      "  - qwen_3b_brazil_1k_balanced_layer_6.pkl -> brazilian/qwen_3b_brazil_1k_balanced_layer_6.pkl\n",
      "  - qwen_3b_brazil_1k_balanced_layer_9.pkl -> brazilian/qwen_3b_brazil_1k_balanced_layer_9.pkl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k.jsonl -> brazilian/qwen_3b_brazil_prompted_balanced_1k.jsonl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k_layer_0.pkl -> brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_0.pkl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k_layer_12.pkl -> brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_12.pkl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k_layer_15.pkl -> brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_15.pkl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k_layer_18.pkl -> brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_18.pkl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k_layer_21.pkl -> brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_21.pkl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k_layer_24.pkl -> brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_24.pkl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k_layer_27.pkl -> brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_27.pkl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k_layer_3.pkl -> brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_3.pkl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k_layer_6.pkl -> brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_6.pkl\n",
      "  - qwen_3b_brazil_prompted_balanced_1k_layer_9.pkl -> brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_9.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Successfully moved 44 files into 'brazilian/'!\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/metaphors-activations/commit/06c81e13dbe679dd8289f1c6606f1565fe8a113c\n",
      "Found 44 files to rename:\n",
      "  - brazilian/llama_3b_brazil_1k_balanced.jsonl -> brazilian/llama_3b_1k_balanced.jsonl\n",
      "  - brazilian/llama_3b_brazil_1k_balanced_layer_0.pkl -> brazilian/llama_3b_1k_balanced_layer_0.pkl\n",
      "  - brazilian/llama_3b_brazil_1k_balanced_layer_12.pkl -> brazilian/llama_3b_1k_balanced_layer_12.pkl\n",
      "  - brazilian/llama_3b_brazil_1k_balanced_layer_15.pkl -> brazilian/llama_3b_1k_balanced_layer_15.pkl\n",
      "  - brazilian/llama_3b_brazil_1k_balanced_layer_18.pkl -> brazilian/llama_3b_1k_balanced_layer_18.pkl\n",
      "  - brazilian/llama_3b_brazil_1k_balanced_layer_21.pkl -> brazilian/llama_3b_1k_balanced_layer_21.pkl\n",
      "  - brazilian/llama_3b_brazil_1k_balanced_layer_24.pkl -> brazilian/llama_3b_1k_balanced_layer_24.pkl\n",
      "  - brazilian/llama_3b_brazil_1k_balanced_layer_27.pkl -> brazilian/llama_3b_1k_balanced_layer_27.pkl\n",
      "  - brazilian/llama_3b_brazil_1k_balanced_layer_3.pkl -> brazilian/llama_3b_1k_balanced_layer_3.pkl\n",
      "  - brazilian/llama_3b_brazil_1k_balanced_layer_6.pkl -> brazilian/llama_3b_1k_balanced_layer_6.pkl\n",
      "  - brazilian/llama_3b_brazil_1k_balanced_layer_9.pkl -> brazilian/llama_3b_1k_balanced_layer_9.pkl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k.jsonl -> brazilian/llama_3b_prompted_balanced_1k.jsonl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k_layer_0.pkl -> brazilian/llama_3b_prompted_balanced_1k_layer_0.pkl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k_layer_12.pkl -> brazilian/llama_3b_prompted_balanced_1k_layer_12.pkl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k_layer_15.pkl -> brazilian/llama_3b_prompted_balanced_1k_layer_15.pkl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k_layer_18.pkl -> brazilian/llama_3b_prompted_balanced_1k_layer_18.pkl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k_layer_21.pkl -> brazilian/llama_3b_prompted_balanced_1k_layer_21.pkl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k_layer_24.pkl -> brazilian/llama_3b_prompted_balanced_1k_layer_24.pkl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k_layer_27.pkl -> brazilian/llama_3b_prompted_balanced_1k_layer_27.pkl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k_layer_3.pkl -> brazilian/llama_3b_prompted_balanced_1k_layer_3.pkl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k_layer_6.pkl -> brazilian/llama_3b_prompted_balanced_1k_layer_6.pkl\n",
      "  - brazilian/llama_3b_brazil_prompted_balanced_1k_layer_9.pkl -> brazilian/llama_3b_prompted_balanced_1k_layer_9.pkl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced.jsonl -> brazilian/qwen_3b_1k_balanced.jsonl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced_layer_0.pkl -> brazilian/qwen_3b_1k_balanced_layer_0.pkl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced_layer_12.pkl -> brazilian/qwen_3b_1k_balanced_layer_12.pkl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced_layer_15.pkl -> brazilian/qwen_3b_1k_balanced_layer_15.pkl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced_layer_18.pkl -> brazilian/qwen_3b_1k_balanced_layer_18.pkl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced_layer_21.pkl -> brazilian/qwen_3b_1k_balanced_layer_21.pkl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced_layer_24.pkl -> brazilian/qwen_3b_1k_balanced_layer_24.pkl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced_layer_27.pkl -> brazilian/qwen_3b_1k_balanced_layer_27.pkl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced_layer_3.pkl -> brazilian/qwen_3b_1k_balanced_layer_3.pkl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced_layer_6.pkl -> brazilian/qwen_3b_1k_balanced_layer_6.pkl\n",
      "  - brazilian/qwen_3b_brazil_1k_balanced_layer_9.pkl -> brazilian/qwen_3b_1k_balanced_layer_9.pkl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k.jsonl -> brazilian/qwen_3b_prompted_balanced_1k.jsonl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_0.pkl -> brazilian/qwen_3b_prompted_balanced_1k_layer_0.pkl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_12.pkl -> brazilian/qwen_3b_prompted_balanced_1k_layer_12.pkl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_15.pkl -> brazilian/qwen_3b_prompted_balanced_1k_layer_15.pkl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_18.pkl -> brazilian/qwen_3b_prompted_balanced_1k_layer_18.pkl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_21.pkl -> brazilian/qwen_3b_prompted_balanced_1k_layer_21.pkl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_24.pkl -> brazilian/qwen_3b_prompted_balanced_1k_layer_24.pkl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_27.pkl -> brazilian/qwen_3b_prompted_balanced_1k_layer_27.pkl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_3.pkl -> brazilian/qwen_3b_prompted_balanced_1k_layer_3.pkl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_6.pkl -> brazilian/qwen_3b_prompted_balanced_1k_layer_6.pkl\n",
      "  - brazilian/qwen_3b_brazil_prompted_balanced_1k_layer_9.pkl -> brazilian/qwen_3b_prompted_balanced_1k_layer_9.pkl\n",
      "Found 40 files to move:\n",
      "  - brazilian/llama_3b_1k_balanced_layer_0.pkl -> brazilian/llama_3b/llama_3b_1k_balanced_layer_0.pkl\n",
      "  - brazilian/llama_3b_1k_balanced_layer_12.pkl -> brazilian/llama_3b/llama_3b_1k_balanced_layer_12.pkl\n",
      "  - brazilian/llama_3b_1k_balanced_layer_15.pkl -> brazilian/llama_3b/llama_3b_1k_balanced_layer_15.pkl\n",
      "  - brazilian/llama_3b_1k_balanced_layer_18.pkl -> brazilian/llama_3b/llama_3b_1k_balanced_layer_18.pkl\n",
      "  - brazilian/llama_3b_1k_balanced_layer_21.pkl -> brazilian/llama_3b/llama_3b_1k_balanced_layer_21.pkl\n",
      "  - brazilian/llama_3b_1k_balanced_layer_24.pkl -> brazilian/llama_3b/llama_3b_1k_balanced_layer_24.pkl\n",
      "  - brazilian/llama_3b_1k_balanced_layer_27.pkl -> brazilian/llama_3b/llama_3b_1k_balanced_layer_27.pkl\n",
      "  - brazilian/llama_3b_1k_balanced_layer_3.pkl -> brazilian/llama_3b/llama_3b_1k_balanced_layer_3.pkl\n",
      "  - brazilian/llama_3b_1k_balanced_layer_6.pkl -> brazilian/llama_3b/llama_3b_1k_balanced_layer_6.pkl\n",
      "  - brazilian/llama_3b_1k_balanced_layer_9.pkl -> brazilian/llama_3b/llama_3b_1k_balanced_layer_9.pkl\n",
      "  - brazilian/llama_3b_prompted_balanced_1k_layer_0.pkl -> brazilian/llama_3b/llama_3b_prompted_balanced_1k_layer_0.pkl\n",
      "  - brazilian/llama_3b_prompted_balanced_1k_layer_12.pkl -> brazilian/llama_3b/llama_3b_prompted_balanced_1k_layer_12.pkl\n",
      "  - brazilian/llama_3b_prompted_balanced_1k_layer_15.pkl -> brazilian/llama_3b/llama_3b_prompted_balanced_1k_layer_15.pkl\n",
      "  - brazilian/llama_3b_prompted_balanced_1k_layer_18.pkl -> brazilian/llama_3b/llama_3b_prompted_balanced_1k_layer_18.pkl\n",
      "  - brazilian/llama_3b_prompted_balanced_1k_layer_21.pkl -> brazilian/llama_3b/llama_3b_prompted_balanced_1k_layer_21.pkl\n",
      "  - brazilian/llama_3b_prompted_balanced_1k_layer_24.pkl -> brazilian/llama_3b/llama_3b_prompted_balanced_1k_layer_24.pkl\n",
      "  - brazilian/llama_3b_prompted_balanced_1k_layer_27.pkl -> brazilian/llama_3b/llama_3b_prompted_balanced_1k_layer_27.pkl\n",
      "  - brazilian/llama_3b_prompted_balanced_1k_layer_3.pkl -> brazilian/llama_3b/llama_3b_prompted_balanced_1k_layer_3.pkl\n",
      "  - brazilian/llama_3b_prompted_balanced_1k_layer_6.pkl -> brazilian/llama_3b/llama_3b_prompted_balanced_1k_layer_6.pkl\n",
      "  - brazilian/llama_3b_prompted_balanced_1k_layer_9.pkl -> brazilian/llama_3b/llama_3b_prompted_balanced_1k_layer_9.pkl\n",
      "  - brazilian/qwen_3b_1k_balanced_layer_0.pkl -> brazilian/llama_3b/qwen_3b_1k_balanced_layer_0.pkl\n",
      "  - brazilian/qwen_3b_1k_balanced_layer_12.pkl -> brazilian/llama_3b/qwen_3b_1k_balanced_layer_12.pkl\n",
      "  - brazilian/qwen_3b_1k_balanced_layer_15.pkl -> brazilian/llama_3b/qwen_3b_1k_balanced_layer_15.pkl\n",
      "  - brazilian/qwen_3b_1k_balanced_layer_18.pkl -> brazilian/llama_3b/qwen_3b_1k_balanced_layer_18.pkl\n",
      "  - brazilian/qwen_3b_1k_balanced_layer_21.pkl -> brazilian/llama_3b/qwen_3b_1k_balanced_layer_21.pkl\n",
      "  - brazilian/qwen_3b_1k_balanced_layer_24.pkl -> brazilian/llama_3b/qwen_3b_1k_balanced_layer_24.pkl\n",
      "  - brazilian/qwen_3b_1k_balanced_layer_27.pkl -> brazilian/llama_3b/qwen_3b_1k_balanced_layer_27.pkl\n",
      "  - brazilian/qwen_3b_1k_balanced_layer_3.pkl -> brazilian/llama_3b/qwen_3b_1k_balanced_layer_3.pkl\n",
      "  - brazilian/qwen_3b_1k_balanced_layer_6.pkl -> brazilian/llama_3b/qwen_3b_1k_balanced_layer_6.pkl\n",
      "  - brazilian/qwen_3b_1k_balanced_layer_9.pkl -> brazilian/llama_3b/qwen_3b_1k_balanced_layer_9.pkl\n",
      "  - brazilian/qwen_3b_prompted_balanced_1k_layer_0.pkl -> brazilian/llama_3b/qwen_3b_prompted_balanced_1k_layer_0.pkl\n",
      "  - brazilian/qwen_3b_prompted_balanced_1k_layer_12.pkl -> brazilian/llama_3b/qwen_3b_prompted_balanced_1k_layer_12.pkl\n",
      "  - brazilian/qwen_3b_prompted_balanced_1k_layer_15.pkl -> brazilian/llama_3b/qwen_3b_prompted_balanced_1k_layer_15.pkl\n",
      "  - brazilian/qwen_3b_prompted_balanced_1k_layer_18.pkl -> brazilian/llama_3b/qwen_3b_prompted_balanced_1k_layer_18.pkl\n",
      "  - brazilian/qwen_3b_prompted_balanced_1k_layer_21.pkl -> brazilian/llama_3b/qwen_3b_prompted_balanced_1k_layer_21.pkl\n",
      "  - brazilian/qwen_3b_prompted_balanced_1k_layer_24.pkl -> brazilian/llama_3b/qwen_3b_prompted_balanced_1k_layer_24.pkl\n",
      "  - brazilian/qwen_3b_prompted_balanced_1k_layer_27.pkl -> brazilian/llama_3b/qwen_3b_prompted_balanced_1k_layer_27.pkl\n",
      "  - brazilian/qwen_3b_prompted_balanced_1k_layer_3.pkl -> brazilian/llama_3b/qwen_3b_prompted_balanced_1k_layer_3.pkl\n",
      "  - brazilian/qwen_3b_prompted_balanced_1k_layer_6.pkl -> brazilian/llama_3b/qwen_3b_prompted_balanced_1k_layer_6.pkl\n",
      "  - brazilian/qwen_3b_prompted_balanced_1k_layer_9.pkl -> brazilian/llama_3b/qwen_3b_prompted_balanced_1k_layer_9.pkl\n",
      "\n",
      "✓ Successfully moved 40 files into 'brazilian/llama_3b/'!\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/metaphors-activations/commit/755cb554c1a202bc3c7e3c3286856b608dae141d\n"
     ]
    }
   ],
   "source": [
    "move_all_to_folder(\"brazilian\", repo_id, match=\"brazil\")\n",
    "success = rename_files_in_hf_dataset(repo_id, \"_brazil\", \"\")\n",
    "move_all_to_folder(\"llama_3b\", repo_id, source_folder=\"brazilian\", match=\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76f3a508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 files to move:\n",
      "  - jailbreaks/llama_3b_balanced_1800_layer_0.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1800_layer_0.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1800_layer_12.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1800_layer_12.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1800_layer_15.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1800_layer_15.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1800_layer_18.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1800_layer_18.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1800_layer_21.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1800_layer_21.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1800_layer_24.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1800_layer_24.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1800_layer_27.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1800_layer_27.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1800_layer_3.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1800_layer_3.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1800_layer_6.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1800_layer_6.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1800_layer_9.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1800_layer_9.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1k_test_layer_0.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1k_test_layer_0.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1k_test_layer_12.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1k_test_layer_12.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1k_test_layer_15.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1k_test_layer_15.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1k_test_layer_18.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1k_test_layer_18.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1k_test_layer_21.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1k_test_layer_21.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1k_test_layer_24.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1k_test_layer_24.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1k_test_layer_27.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1k_test_layer_27.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1k_test_layer_3.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1k_test_layer_3.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1k_test_layer_6.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1k_test_layer_6.pkl\n",
      "  - jailbreaks/llama_3b_balanced_1k_test_layer_9.pkl -> jailbreaks/llama_3b/llama_3b_balanced_1k_test_layer_9.pkl\n",
      "  - jailbreaks/ministral-8b_balanced_1k_test_layer_0.pkl -> jailbreaks/llama_3b/ministral-8b_balanced_1k_test_layer_0.pkl\n",
      "  - jailbreaks/ministral-8b_balanced_1k_test_layer_12.pkl -> jailbreaks/llama_3b/ministral-8b_balanced_1k_test_layer_12.pkl\n",
      "  - jailbreaks/ministral-8b_balanced_1k_test_layer_15.pkl -> jailbreaks/llama_3b/ministral-8b_balanced_1k_test_layer_15.pkl\n",
      "  - jailbreaks/ministral-8b_balanced_1k_test_layer_18.pkl -> jailbreaks/llama_3b/ministral-8b_balanced_1k_test_layer_18.pkl\n",
      "  - jailbreaks/ministral-8b_balanced_1k_test_layer_21.pkl -> jailbreaks/llama_3b/ministral-8b_balanced_1k_test_layer_21.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Successfully moved 25 files into 'jailbreaks/llama_3b/'!\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/refusal-activations/commit/92042c5d17c5d82a0ddd5caf34aa0f2e702cbe7a\n"
     ]
    }
   ],
   "source": [
    "# move_all_to_folder(\"brazilian\", repo_id, match=\"brazil\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"_brazil\", \"\")\n",
    "move_all_to_folder(\"llama_3b\", repo_id, source_folder=\"jailbreaks\", match=\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ceee5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 files to move:\n",
      "  - llama_3b_shakespeare_15k.jsonl -> shakespeare/llama_3b_shakespeare_15k.jsonl\n",
      "  - llama_3b_shakespeare_45k.jsonl -> shakespeare/llama_3b_shakespeare_45k.jsonl\n",
      "  - llama_3b_shakespeare_balanced_1k.jsonl -> shakespeare/llama_3b_shakespeare_balanced_1k.jsonl\n",
      "  - llama_3b_shakespeare_balanced_1k_layer_0.pkl -> shakespeare/llama_3b_shakespeare_balanced_1k_layer_0.pkl\n",
      "  - llama_3b_shakespeare_balanced_1k_layer_12.pkl -> shakespeare/llama_3b_shakespeare_balanced_1k_layer_12.pkl\n",
      "  - llama_3b_shakespeare_balanced_1k_layer_15.pkl -> shakespeare/llama_3b_shakespeare_balanced_1k_layer_15.pkl\n",
      "  - llama_3b_shakespeare_balanced_1k_layer_18.pkl -> shakespeare/llama_3b_shakespeare_balanced_1k_layer_18.pkl\n",
      "  - llama_3b_shakespeare_balanced_1k_layer_21.pkl -> shakespeare/llama_3b_shakespeare_balanced_1k_layer_21.pkl\n",
      "  - llama_3b_shakespeare_balanced_1k_layer_24.pkl -> shakespeare/llama_3b_shakespeare_balanced_1k_layer_24.pkl\n",
      "  - llama_3b_shakespeare_balanced_1k_layer_27.pkl -> shakespeare/llama_3b_shakespeare_balanced_1k_layer_27.pkl\n",
      "  - llama_3b_shakespeare_balanced_1k_layer_3.pkl -> shakespeare/llama_3b_shakespeare_balanced_1k_layer_3.pkl\n",
      "  - llama_3b_shakespeare_balanced_1k_layer_6.pkl -> shakespeare/llama_3b_shakespeare_balanced_1k_layer_6.pkl\n",
      "  - llama_3b_shakespeare_balanced_1k_layer_9.pkl -> shakespeare/llama_3b_shakespeare_balanced_1k_layer_9.pkl\n",
      "  - qwen_3b_shakespeare_15k.jsonl -> shakespeare/qwen_3b_shakespeare_15k.jsonl\n",
      "  - qwen_3b_shakespeare_45k.jsonl -> shakespeare/qwen_3b_shakespeare_45k.jsonl\n",
      "  - shakespeare_15k.jsonl -> shakespeare/shakespeare_15k.jsonl\n",
      "  - shakespeare_45k.jsonl -> shakespeare/shakespeare_45k.jsonl\n",
      "\n",
      "✓ Successfully moved 17 files into 'shakespeare/'!\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/metaphors-activations/commit/043b75b848fbe2b369fd3708171e9e59bcb12f17\n",
      "Found 15 files to rename:\n",
      "  - shakespeare/llama_3b_shakespeare_15k.jsonl -> shakespeare/llama_3b_15k.jsonl\n",
      "  - shakespeare/llama_3b_shakespeare_45k.jsonl -> shakespeare/llama_3b_45k.jsonl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k.jsonl -> shakespeare/llama_3b_balanced_1k.jsonl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k_layer_0.pkl -> shakespeare/llama_3b_balanced_1k_layer_0.pkl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k_layer_12.pkl -> shakespeare/llama_3b_balanced_1k_layer_12.pkl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k_layer_15.pkl -> shakespeare/llama_3b_balanced_1k_layer_15.pkl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k_layer_18.pkl -> shakespeare/llama_3b_balanced_1k_layer_18.pkl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k_layer_21.pkl -> shakespeare/llama_3b_balanced_1k_layer_21.pkl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k_layer_24.pkl -> shakespeare/llama_3b_balanced_1k_layer_24.pkl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k_layer_27.pkl -> shakespeare/llama_3b_balanced_1k_layer_27.pkl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k_layer_3.pkl -> shakespeare/llama_3b_balanced_1k_layer_3.pkl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k_layer_6.pkl -> shakespeare/llama_3b_balanced_1k_layer_6.pkl\n",
      "  - shakespeare/llama_3b_shakespeare_balanced_1k_layer_9.pkl -> shakespeare/llama_3b_balanced_1k_layer_9.pkl\n",
      "  - shakespeare/qwen_3b_shakespeare_15k.jsonl -> shakespeare/qwen_3b_15k.jsonl\n",
      "  - shakespeare/qwen_3b_shakespeare_45k.jsonl -> shakespeare/qwen_3b_45k.jsonl\n",
      "Found 10 files to move:\n",
      "  - shakespeare/llama_3b_balanced_1k_layer_0.pkl -> shakespeare/llama_3b/llama_3b_balanced_1k_layer_0.pkl\n",
      "  - shakespeare/llama_3b_balanced_1k_layer_12.pkl -> shakespeare/llama_3b/llama_3b_balanced_1k_layer_12.pkl\n",
      "  - shakespeare/llama_3b_balanced_1k_layer_15.pkl -> shakespeare/llama_3b/llama_3b_balanced_1k_layer_15.pkl\n",
      "  - shakespeare/llama_3b_balanced_1k_layer_18.pkl -> shakespeare/llama_3b/llama_3b_balanced_1k_layer_18.pkl\n",
      "  - shakespeare/llama_3b_balanced_1k_layer_21.pkl -> shakespeare/llama_3b/llama_3b_balanced_1k_layer_21.pkl\n",
      "  - shakespeare/llama_3b_balanced_1k_layer_24.pkl -> shakespeare/llama_3b/llama_3b_balanced_1k_layer_24.pkl\n",
      "  - shakespeare/llama_3b_balanced_1k_layer_27.pkl -> shakespeare/llama_3b/llama_3b_balanced_1k_layer_27.pkl\n",
      "  - shakespeare/llama_3b_balanced_1k_layer_3.pkl -> shakespeare/llama_3b/llama_3b_balanced_1k_layer_3.pkl\n",
      "  - shakespeare/llama_3b_balanced_1k_layer_6.pkl -> shakespeare/llama_3b/llama_3b_balanced_1k_layer_6.pkl\n",
      "  - shakespeare/llama_3b_balanced_1k_layer_9.pkl -> shakespeare/llama_3b/llama_3b_balanced_1k_layer_9.pkl\n",
      "\n",
      "✓ Successfully moved 10 files into 'shakespeare/llama_3b/'!\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/metaphors-activations/commit/2948f269d4a5a9093505e10c789b4dee67639d6b\n"
     ]
    }
   ],
   "source": [
    "# move_all_to_folder(\"shakespeare\", repo_id, match=\"ood\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"_ood\", \"\")\n",
    "move_all_to_folder(\"shakespeare\", repo_id, match=\"shakespeare\")\n",
    "success = rename_files_in_hf_dataset(repo_id, \"_shakespeare\", \"\")\n",
    "move_all_to_folder(\"llama_3b\", repo_id, source_folder=\"shakespeare\", match=\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d15ea5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 files to move:\n",
      "  - llama_3b_incentivised_ood_1k_balanced.jsonl -> mmlu/llama_3b_incentivised_ood_1k_balanced.jsonl\n",
      "  - llama_3b_incentivised_ood_1k_balanced_layer_0.pkl -> mmlu/llama_3b_incentivised_ood_1k_balanced_layer_0.pkl\n",
      "  - llama_3b_incentivised_ood_1k_balanced_layer_12.pkl -> mmlu/llama_3b_incentivised_ood_1k_balanced_layer_12.pkl\n",
      "  - llama_3b_incentivised_ood_1k_balanced_layer_15.pkl -> mmlu/llama_3b_incentivised_ood_1k_balanced_layer_15.pkl\n",
      "  - llama_3b_incentivised_ood_1k_balanced_layer_18.pkl -> mmlu/llama_3b_incentivised_ood_1k_balanced_layer_18.pkl\n",
      "  - llama_3b_incentivised_ood_1k_balanced_layer_21.pkl -> mmlu/llama_3b_incentivised_ood_1k_balanced_layer_21.pkl\n",
      "  - llama_3b_incentivised_ood_1k_balanced_layer_24.pkl -> mmlu/llama_3b_incentivised_ood_1k_balanced_layer_24.pkl\n",
      "  - llama_3b_incentivised_ood_1k_balanced_layer_27.pkl -> mmlu/llama_3b_incentivised_ood_1k_balanced_layer_27.pkl\n",
      "  - llama_3b_incentivised_ood_1k_balanced_layer_3.pkl -> mmlu/llama_3b_incentivised_ood_1k_balanced_layer_3.pkl\n",
      "  - llama_3b_incentivised_ood_1k_balanced_layer_6.pkl -> mmlu/llama_3b_incentivised_ood_1k_balanced_layer_6.pkl\n",
      "  - llama_3b_incentivised_ood_1k_balanced_layer_9.pkl -> mmlu/llama_3b_incentivised_ood_1k_balanced_layer_9.pkl\n",
      "  - llama_3b_ood_test_1k_balanced.jsonl -> mmlu/llama_3b_ood_test_1k_balanced.jsonl\n",
      "  - llama_3b_ood_test_1k_balanced_layer_0.pkl -> mmlu/llama_3b_ood_test_1k_balanced_layer_0.pkl\n",
      "  - llama_3b_ood_test_1k_balanced_layer_12.pkl -> mmlu/llama_3b_ood_test_1k_balanced_layer_12.pkl\n",
      "  - llama_3b_ood_test_1k_balanced_layer_15.pkl -> mmlu/llama_3b_ood_test_1k_balanced_layer_15.pkl\n",
      "  - llama_3b_ood_test_1k_balanced_layer_18.pkl -> mmlu/llama_3b_ood_test_1k_balanced_layer_18.pkl\n",
      "  - llama_3b_ood_test_1k_balanced_layer_21.pkl -> mmlu/llama_3b_ood_test_1k_balanced_layer_21.pkl\n",
      "  - llama_3b_ood_test_1k_balanced_layer_24.pkl -> mmlu/llama_3b_ood_test_1k_balanced_layer_24.pkl\n",
      "  - llama_3b_ood_test_1k_balanced_layer_27.pkl -> mmlu/llama_3b_ood_test_1k_balanced_layer_27.pkl\n",
      "  - llama_3b_ood_test_1k_balanced_layer_3.pkl -> mmlu/llama_3b_ood_test_1k_balanced_layer_3.pkl\n",
      "  - llama_3b_ood_test_1k_balanced_layer_6.pkl -> mmlu/llama_3b_ood_test_1k_balanced_layer_6.pkl\n",
      "  - llama_3b_ood_test_1k_balanced_layer_9.pkl -> mmlu/llama_3b_ood_test_1k_balanced_layer_9.pkl\n",
      "\n",
      "✓ Successfully moved 22 files into 'mmlu/'!\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/science-activations/commit/43b96e0aaa7a9df9b6ccd6312caca6fcd358096c\n",
      "Found 22 files to rename:\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced.jsonl -> mmlu/llama_3b_incentivised_1k_balanced.jsonl\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced_layer_0.pkl -> mmlu/llama_3b_incentivised_1k_balanced_layer_0.pkl\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced_layer_12.pkl -> mmlu/llama_3b_incentivised_1k_balanced_layer_12.pkl\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced_layer_15.pkl -> mmlu/llama_3b_incentivised_1k_balanced_layer_15.pkl\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced_layer_18.pkl -> mmlu/llama_3b_incentivised_1k_balanced_layer_18.pkl\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced_layer_21.pkl -> mmlu/llama_3b_incentivised_1k_balanced_layer_21.pkl\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced_layer_24.pkl -> mmlu/llama_3b_incentivised_1k_balanced_layer_24.pkl\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced_layer_27.pkl -> mmlu/llama_3b_incentivised_1k_balanced_layer_27.pkl\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced_layer_3.pkl -> mmlu/llama_3b_incentivised_1k_balanced_layer_3.pkl\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced_layer_6.pkl -> mmlu/llama_3b_incentivised_1k_balanced_layer_6.pkl\n",
      "  - mmlu/llama_3b_incentivised_ood_1k_balanced_layer_9.pkl -> mmlu/llama_3b_incentivised_1k_balanced_layer_9.pkl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced.jsonl -> mmlu/llama_3b_test_1k_balanced.jsonl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced_layer_0.pkl -> mmlu/llama_3b_test_1k_balanced_layer_0.pkl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced_layer_12.pkl -> mmlu/llama_3b_test_1k_balanced_layer_12.pkl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced_layer_15.pkl -> mmlu/llama_3b_test_1k_balanced_layer_15.pkl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced_layer_18.pkl -> mmlu/llama_3b_test_1k_balanced_layer_18.pkl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced_layer_21.pkl -> mmlu/llama_3b_test_1k_balanced_layer_21.pkl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced_layer_24.pkl -> mmlu/llama_3b_test_1k_balanced_layer_24.pkl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced_layer_27.pkl -> mmlu/llama_3b_test_1k_balanced_layer_27.pkl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced_layer_3.pkl -> mmlu/llama_3b_test_1k_balanced_layer_3.pkl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced_layer_6.pkl -> mmlu/llama_3b_test_1k_balanced_layer_6.pkl\n",
      "  - mmlu/llama_3b_ood_test_1k_balanced_layer_9.pkl -> mmlu/llama_3b_test_1k_balanced_layer_9.pkl\n",
      "Found 20 files to move:\n",
      "  - mmlu/llama_3b_incentivised_1k_balanced_layer_0.pkl -> mmlu/llama_3b/llama_3b_incentivised_1k_balanced_layer_0.pkl\n",
      "  - mmlu/llama_3b_incentivised_1k_balanced_layer_12.pkl -> mmlu/llama_3b/llama_3b_incentivised_1k_balanced_layer_12.pkl\n",
      "  - mmlu/llama_3b_incentivised_1k_balanced_layer_15.pkl -> mmlu/llama_3b/llama_3b_incentivised_1k_balanced_layer_15.pkl\n",
      "  - mmlu/llama_3b_incentivised_1k_balanced_layer_18.pkl -> mmlu/llama_3b/llama_3b_incentivised_1k_balanced_layer_18.pkl\n",
      "  - mmlu/llama_3b_incentivised_1k_balanced_layer_21.pkl -> mmlu/llama_3b/llama_3b_incentivised_1k_balanced_layer_21.pkl\n",
      "  - mmlu/llama_3b_incentivised_1k_balanced_layer_24.pkl -> mmlu/llama_3b/llama_3b_incentivised_1k_balanced_layer_24.pkl\n",
      "  - mmlu/llama_3b_incentivised_1k_balanced_layer_27.pkl -> mmlu/llama_3b/llama_3b_incentivised_1k_balanced_layer_27.pkl\n",
      "  - mmlu/llama_3b_incentivised_1k_balanced_layer_3.pkl -> mmlu/llama_3b/llama_3b_incentivised_1k_balanced_layer_3.pkl\n",
      "  - mmlu/llama_3b_incentivised_1k_balanced_layer_6.pkl -> mmlu/llama_3b/llama_3b_incentivised_1k_balanced_layer_6.pkl\n",
      "  - mmlu/llama_3b_incentivised_1k_balanced_layer_9.pkl -> mmlu/llama_3b/llama_3b_incentivised_1k_balanced_layer_9.pkl\n",
      "  - mmlu/llama_3b_test_1k_balanced_layer_0.pkl -> mmlu/llama_3b/llama_3b_test_1k_balanced_layer_0.pkl\n",
      "  - mmlu/llama_3b_test_1k_balanced_layer_12.pkl -> mmlu/llama_3b/llama_3b_test_1k_balanced_layer_12.pkl\n",
      "  - mmlu/llama_3b_test_1k_balanced_layer_15.pkl -> mmlu/llama_3b/llama_3b_test_1k_balanced_layer_15.pkl\n",
      "  - mmlu/llama_3b_test_1k_balanced_layer_18.pkl -> mmlu/llama_3b/llama_3b_test_1k_balanced_layer_18.pkl\n",
      "  - mmlu/llama_3b_test_1k_balanced_layer_21.pkl -> mmlu/llama_3b/llama_3b_test_1k_balanced_layer_21.pkl\n",
      "  - mmlu/llama_3b_test_1k_balanced_layer_24.pkl -> mmlu/llama_3b/llama_3b_test_1k_balanced_layer_24.pkl\n",
      "  - mmlu/llama_3b_test_1k_balanced_layer_27.pkl -> mmlu/llama_3b/llama_3b_test_1k_balanced_layer_27.pkl\n",
      "  - mmlu/llama_3b_test_1k_balanced_layer_3.pkl -> mmlu/llama_3b/llama_3b_test_1k_balanced_layer_3.pkl\n",
      "  - mmlu/llama_3b_test_1k_balanced_layer_6.pkl -> mmlu/llama_3b/llama_3b_test_1k_balanced_layer_6.pkl\n",
      "  - mmlu/llama_3b_test_1k_balanced_layer_9.pkl -> mmlu/llama_3b/llama_3b_test_1k_balanced_layer_9.pkl\n",
      "\n",
      "✓ Successfully moved 20 files into 'mmlu/llama_3b/'!\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/science-activations/commit/165af10fcc7aa44b8dd02db252281712cbaeffdf\n"
     ]
    }
   ],
   "source": [
    "move_all_to_folder(\"mmlu\", repo_id, match=\"ood\")\n",
    "success = rename_files_in_hf_dataset(repo_id, \"_ood\", \"\")\n",
    "move_all_to_folder(\"llama_3b\", repo_id, source_folder=\"mmlu\", match=\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19274dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 files to move:\n",
      "  - jailbreaks/ministral_8b_on_policy_test_layer_24.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_test_layer_24.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_test_layer_27.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_test_layer_27.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_test_layer_3.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_test_layer_3.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_test_layer_6.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_test_layer_6.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_test_layer_9.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_test_layer_9.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_train_layer_0.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_0.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_train_layer_12.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_12.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_train_layer_15.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_15.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_train_layer_18.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_18.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_train_layer_21.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_21.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_train_layer_24.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_24.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_train_layer_27.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_27.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_train_layer_3.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_3.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_train_layer_6.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_6.pkl\n",
      "  - jailbreaks/ministral_8b_on_policy_train_layer_9.pkl -> jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_9.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Successfully moved 15 files into 'jailbreaks/llama_3b/'!\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/refusal-activations/commit/d82bd56b623f36c502e64ae3883c22c02c7d6c0c\n"
     ]
    }
   ],
   "source": [
    "move_all_to_folder(\"jailbreaks\", repo_id, source_folder=\"\")\n",
    "move_all_to_folder(\"llama_3b\", repo_id, source_folder=\"jailbreaks\", match=\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5bfe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 files to rename:\n",
      "  - roleplaying/llama_3b/llama_3b_3.5k_layer_0.pkl -> roleplaying/llama_3b/llama_3b_incentivised_3.5k_layer_0.pkl\n",
      "  - roleplaying/llama_3b/llama_3b_3.5k_layer_12.pkl -> roleplaying/llama_3b/llama_3b_incentivised_3.5k_layer_12.pkl\n",
      "  - roleplaying/llama_3b/llama_3b_3.5k_layer_15.pkl -> roleplaying/llama_3b/llama_3b_incentivised_3.5k_layer_15.pkl\n",
      "  - roleplaying/llama_3b/llama_3b_3.5k_layer_18.pkl -> roleplaying/llama_3b/llama_3b_incentivised_3.5k_layer_18.pkl\n",
      "  - roleplaying/llama_3b/llama_3b_3.5k_layer_21.pkl -> roleplaying/llama_3b/llama_3b_incentivised_3.5k_layer_21.pkl\n",
      "  - roleplaying/llama_3b/llama_3b_3.5k_layer_24.pkl -> roleplaying/llama_3b/llama_3b_incentivised_3.5k_layer_24.pkl\n",
      "  - roleplaying/llama_3b/llama_3b_3.5k_layer_27.pkl -> roleplaying/llama_3b/llama_3b_incentivised_3.5k_layer_27.pkl\n",
      "  - roleplaying/llama_3b/llama_3b_3.5k_layer_3.pkl -> roleplaying/llama_3b/llama_3b_incentivised_3.5k_layer_3.pkl\n",
      "  - roleplaying/llama_3b/llama_3b_3.5k_layer_6.pkl -> roleplaying/llama_3b/llama_3b_incentivised_3.5k_layer_6.pkl\n",
      "  - roleplaying/llama_3b/llama_3b_3.5k_layer_9.pkl -> roleplaying/llama_3b/llama_3b_incentivised_3.5k_layer_9.pkl\n",
      "  - roleplaying/llama_3b_3.5k.jsonl -> roleplaying/llama_3b_incentivised_3.5k.jsonl\n",
      "  - trading/llama_3b/llama_3b_3.5k_layer_12.pkl -> trading/llama_3b/llama_3b_incentivised_3.5k_layer_12.pkl\n",
      "  - trading/llama_3b/llama_3b_3.5k_layer_15.pkl -> trading/llama_3b/llama_3b_incentivised_3.5k_layer_15.pkl\n",
      "  - trading/llama_3b/llama_3b_3.5k_layer_18.pkl -> trading/llama_3b/llama_3b_incentivised_3.5k_layer_18.pkl\n",
      "  - trading/llama_3b/llama_3b_3.5k_layer_9.pkl -> trading/llama_3b/llama_3b_incentivised_3.5k_layer_9.pkl\n",
      "  - trading/llama_3b_3.5k.jsonl -> trading/llama_3b_incentivised_3.5k.jsonl\n",
      "Found 5 files to rename:\n",
      "  - trading/deepseek_mixtral_3.5k.jsonl -> trading/deepseek_mixtral_off_policy_3.5k.jsonl\n",
      "  - trading/llama_3b/deepseek_mixtral_3.5k_layer_12.pkl -> trading/llama_3b/deepseek_mixtral_off_policy_3.5k_layer_12.pkl\n",
      "  - trading/llama_3b/deepseek_mixtral_3.5k_layer_15.pkl -> trading/llama_3b/deepseek_mixtral_off_policy_3.5k_layer_15.pkl\n",
      "  - trading/llama_3b/deepseek_mixtral_3.5k_layer_18.pkl -> trading/llama_3b/deepseek_mixtral_off_policy_3.5k_layer_18.pkl\n",
      "  - trading/llama_3b/deepseek_mixtral_3.5k_layer_9.pkl -> trading/llama_3b/deepseek_mixtral_off_policy_3.5k_layer_9.pkl\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"lasrprobegen/deception-activations\"\n",
    "success = rename_files_in_hf_dataset(repo_id, \"llama_3b_on_policy\", \"llama_3b_incentivised\")\n",
    "success = rename_files_in_hf_dataset(repo_id, \"mistral_7b_on_policy\", \"mistral_7b_off_policy\")\n",
    "\n",
    "success = rename_files_in_hf_dataset(repo_id, \"llama_3b_3.5k\", \"llama_3b_incentivised_3.5k\")\n",
    "success = rename_files_in_hf_dataset(repo_id, \"deepseek_mixtral_3.5k\", \"deepseek_mixtral_off_policy_3.5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f14a12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 files to rename:\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_test_layer_0.pkl -> multichoice/llama_3b/llama_3b_incentivised_test_layer_0.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_test_layer_12.pkl -> multichoice/llama_3b/llama_3b_incentivised_test_layer_12.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_test_layer_15.pkl -> multichoice/llama_3b/llama_3b_incentivised_test_layer_15.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_test_layer_18.pkl -> multichoice/llama_3b/llama_3b_incentivised_test_layer_18.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_test_layer_21.pkl -> multichoice/llama_3b/llama_3b_incentivised_test_layer_21.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_test_layer_24.pkl -> multichoice/llama_3b/llama_3b_incentivised_test_layer_24.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_test_layer_27.pkl -> multichoice/llama_3b/llama_3b_incentivised_test_layer_27.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_test_layer_3.pkl -> multichoice/llama_3b/llama_3b_incentivised_test_layer_3.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_test_layer_6.pkl -> multichoice/llama_3b/llama_3b_incentivised_test_layer_6.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_test_layer_9.pkl -> multichoice/llama_3b/llama_3b_incentivised_test_layer_9.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_train_layer_0.pkl -> multichoice/llama_3b/llama_3b_incentivised_train_layer_0.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_train_layer_12.pkl -> multichoice/llama_3b/llama_3b_incentivised_train_layer_12.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_train_layer_15.pkl -> multichoice/llama_3b/llama_3b_incentivised_train_layer_15.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_train_layer_18.pkl -> multichoice/llama_3b/llama_3b_incentivised_train_layer_18.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_train_layer_21.pkl -> multichoice/llama_3b/llama_3b_incentivised_train_layer_21.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_train_layer_24.pkl -> multichoice/llama_3b/llama_3b_incentivised_train_layer_24.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_train_layer_27.pkl -> multichoice/llama_3b/llama_3b_incentivised_train_layer_27.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_train_layer_3.pkl -> multichoice/llama_3b/llama_3b_incentivised_train_layer_3.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_train_layer_6.pkl -> multichoice/llama_3b/llama_3b_incentivised_train_layer_6.pkl\n",
      "  - multichoice/llama_3b/llama_3b_on_policy_train_layer_9.pkl -> multichoice/llama_3b/llama_3b_incentivised_train_layer_9.pkl\n",
      "  - multichoice/llama_3b_on_policy_test.jsonl -> multichoice/llama_3b_incentivised_test.jsonl\n",
      "  - multichoice/llama_3b_on_policy_train.jsonl -> multichoice/llama_3b_incentivised_train.jsonl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_3.5k_layer_0.pkl -> wmd/llama_3b/llama_3b_incentivised_3.5k_layer_0.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_3.5k_layer_12.pkl -> wmd/llama_3b/llama_3b_incentivised_3.5k_layer_12.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_3.5k_layer_15.pkl -> wmd/llama_3b/llama_3b_incentivised_3.5k_layer_15.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_3.5k_layer_18.pkl -> wmd/llama_3b/llama_3b_incentivised_3.5k_layer_18.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_3.5k_layer_21.pkl -> wmd/llama_3b/llama_3b_incentivised_3.5k_layer_21.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_3.5k_layer_24.pkl -> wmd/llama_3b/llama_3b_incentivised_3.5k_layer_24.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_3.5k_layer_27.pkl -> wmd/llama_3b/llama_3b_incentivised_3.5k_layer_27.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_3.5k_layer_3.pkl -> wmd/llama_3b/llama_3b_incentivised_3.5k_layer_3.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_3.5k_layer_6.pkl -> wmd/llama_3b/llama_3b_incentivised_3.5k_layer_6.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_3.5k_layer_9.pkl -> wmd/llama_3b/llama_3b_incentivised_3.5k_layer_9.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_test_layer_0.pkl -> wmd/llama_3b/llama_3b_incentivised_test_layer_0.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_test_layer_12.pkl -> wmd/llama_3b/llama_3b_incentivised_test_layer_12.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_test_layer_15.pkl -> wmd/llama_3b/llama_3b_incentivised_test_layer_15.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_test_layer_18.pkl -> wmd/llama_3b/llama_3b_incentivised_test_layer_18.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_test_layer_21.pkl -> wmd/llama_3b/llama_3b_incentivised_test_layer_21.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_test_layer_24.pkl -> wmd/llama_3b/llama_3b_incentivised_test_layer_24.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_test_layer_27.pkl -> wmd/llama_3b/llama_3b_incentivised_test_layer_27.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_test_layer_3.pkl -> wmd/llama_3b/llama_3b_incentivised_test_layer_3.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_test_layer_6.pkl -> wmd/llama_3b/llama_3b_incentivised_test_layer_6.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_test_layer_9.pkl -> wmd/llama_3b/llama_3b_incentivised_test_layer_9.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_train_layer_0.pkl -> wmd/llama_3b/llama_3b_incentivised_train_layer_0.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_train_layer_12.pkl -> wmd/llama_3b/llama_3b_incentivised_train_layer_12.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_train_layer_15.pkl -> wmd/llama_3b/llama_3b_incentivised_train_layer_15.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_train_layer_18.pkl -> wmd/llama_3b/llama_3b_incentivised_train_layer_18.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_train_layer_21.pkl -> wmd/llama_3b/llama_3b_incentivised_train_layer_21.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_train_layer_24.pkl -> wmd/llama_3b/llama_3b_incentivised_train_layer_24.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_train_layer_27.pkl -> wmd/llama_3b/llama_3b_incentivised_train_layer_27.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_train_layer_3.pkl -> wmd/llama_3b/llama_3b_incentivised_train_layer_3.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_train_layer_6.pkl -> wmd/llama_3b/llama_3b_incentivised_train_layer_6.pkl\n",
      "  - wmd/llama_3b/llama_3b_on_policy_train_layer_9.pkl -> wmd/llama_3b/llama_3b_incentivised_train_layer_9.pkl\n",
      "  - wmd/llama_3b_on_policy_3.5k.jsonl -> wmd/llama_3b_incentivised_3.5k.jsonl\n",
      "  - wmd/llama_3b_on_policy_test.jsonl -> wmd/llama_3b_incentivised_test.jsonl\n",
      "  - wmd/llama_3b_on_policy_train.jsonl -> wmd/llama_3b_incentivised_train.jsonl\n",
      "Found 22 files to rename:\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_test_layer_0.pkl -> multichoice/llama_3b/ministral_8b_off_policy_test_layer_0.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_test_layer_12.pkl -> multichoice/llama_3b/ministral_8b_off_policy_test_layer_12.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_test_layer_15.pkl -> multichoice/llama_3b/ministral_8b_off_policy_test_layer_15.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_test_layer_18.pkl -> multichoice/llama_3b/ministral_8b_off_policy_test_layer_18.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_test_layer_21.pkl -> multichoice/llama_3b/ministral_8b_off_policy_test_layer_21.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_test_layer_24.pkl -> multichoice/llama_3b/ministral_8b_off_policy_test_layer_24.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_test_layer_27.pkl -> multichoice/llama_3b/ministral_8b_off_policy_test_layer_27.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_test_layer_3.pkl -> multichoice/llama_3b/ministral_8b_off_policy_test_layer_3.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_test_layer_6.pkl -> multichoice/llama_3b/ministral_8b_off_policy_test_layer_6.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_test_layer_9.pkl -> multichoice/llama_3b/ministral_8b_off_policy_test_layer_9.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_train_layer_0.pkl -> multichoice/llama_3b/ministral_8b_off_policy_train_layer_0.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_train_layer_12.pkl -> multichoice/llama_3b/ministral_8b_off_policy_train_layer_12.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_train_layer_15.pkl -> multichoice/llama_3b/ministral_8b_off_policy_train_layer_15.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_train_layer_18.pkl -> multichoice/llama_3b/ministral_8b_off_policy_train_layer_18.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_train_layer_21.pkl -> multichoice/llama_3b/ministral_8b_off_policy_train_layer_21.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_train_layer_24.pkl -> multichoice/llama_3b/ministral_8b_off_policy_train_layer_24.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_train_layer_27.pkl -> multichoice/llama_3b/ministral_8b_off_policy_train_layer_27.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_train_layer_3.pkl -> multichoice/llama_3b/ministral_8b_off_policy_train_layer_3.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_train_layer_6.pkl -> multichoice/llama_3b/ministral_8b_off_policy_train_layer_6.pkl\n",
      "  - multichoice/llama_3b/ministral_8b_on_policy_train_layer_9.pkl -> multichoice/llama_3b/ministral_8b_off_policy_train_layer_9.pkl\n",
      "  - multichoice/ministral_8b_on_policy_test.jsonl -> multichoice/ministral_8b_off_policy_test.jsonl\n",
      "  - multichoice/ministral_8b_on_policy_train.jsonl -> multichoice/ministral_8b_off_policy_train.jsonl\n",
      "Found 32 files to rename:\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_3.5k_layer_0.pkl -> wmd/llama_3b/mistral_7b_off_policy_3.5k_layer_0.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_3.5k_layer_12.pkl -> wmd/llama_3b/mistral_7b_off_policy_3.5k_layer_12.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_3.5k_layer_15.pkl -> wmd/llama_3b/mistral_7b_off_policy_3.5k_layer_15.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_3.5k_layer_18.pkl -> wmd/llama_3b/mistral_7b_off_policy_3.5k_layer_18.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_3.5k_layer_24.pkl -> wmd/llama_3b/mistral_7b_off_policy_3.5k_layer_24.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_3.5k_layer_27.pkl -> wmd/llama_3b/mistral_7b_off_policy_3.5k_layer_27.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_3.5k_layer_3.pkl -> wmd/llama_3b/mistral_7b_off_policy_3.5k_layer_3.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_3.5k_layer_6.pkl -> wmd/llama_3b/mistral_7b_off_policy_3.5k_layer_6.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_3.5k_layer_9.pkl -> wmd/llama_3b/mistral_7b_off_policy_3.5k_layer_9.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_test_layer_0.pkl -> wmd/llama_3b/mistral_7b_off_policy_test_layer_0.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_test_layer_12.pkl -> wmd/llama_3b/mistral_7b_off_policy_test_layer_12.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_test_layer_15.pkl -> wmd/llama_3b/mistral_7b_off_policy_test_layer_15.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_test_layer_18.pkl -> wmd/llama_3b/mistral_7b_off_policy_test_layer_18.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_test_layer_21.pkl -> wmd/llama_3b/mistral_7b_off_policy_test_layer_21.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_test_layer_24.pkl -> wmd/llama_3b/mistral_7b_off_policy_test_layer_24.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_test_layer_27.pkl -> wmd/llama_3b/mistral_7b_off_policy_test_layer_27.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_test_layer_3.pkl -> wmd/llama_3b/mistral_7b_off_policy_test_layer_3.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_test_layer_6.pkl -> wmd/llama_3b/mistral_7b_off_policy_test_layer_6.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_test_layer_9.pkl -> wmd/llama_3b/mistral_7b_off_policy_test_layer_9.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_train_layer_0.pkl -> wmd/llama_3b/mistral_7b_off_policy_train_layer_0.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_train_layer_12.pkl -> wmd/llama_3b/mistral_7b_off_policy_train_layer_12.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_train_layer_15.pkl -> wmd/llama_3b/mistral_7b_off_policy_train_layer_15.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_train_layer_18.pkl -> wmd/llama_3b/mistral_7b_off_policy_train_layer_18.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_train_layer_21.pkl -> wmd/llama_3b/mistral_7b_off_policy_train_layer_21.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_train_layer_24.pkl -> wmd/llama_3b/mistral_7b_off_policy_train_layer_24.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_train_layer_27.pkl -> wmd/llama_3b/mistral_7b_off_policy_train_layer_27.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_train_layer_3.pkl -> wmd/llama_3b/mistral_7b_off_policy_train_layer_3.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_train_layer_6.pkl -> wmd/llama_3b/mistral_7b_off_policy_train_layer_6.pkl\n",
      "  - wmd/llama_3b/mistral_7b_on_policy_train_layer_9.pkl -> wmd/llama_3b/mistral_7b_off_policy_train_layer_9.pkl\n",
      "  - wmd/mistral_7b_on_policy_3.5k.jsonl -> wmd/mistral_7b_off_policy_3.5k.jsonl\n",
      "  - wmd/mistral_7b_on_policy_test.jsonl -> wmd/mistral_7b_off_policy_test.jsonl\n",
      "  - wmd/mistral_7b_on_policy_train.jsonl -> wmd/mistral_7b_off_policy_train.jsonl\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"lasrprobegen/sandbagging-activations\"\n",
    "success = rename_files_in_hf_dataset(repo_id, \"llama_3b_on_policy\", \"llama_3b_incentivised\")\n",
    "success = rename_files_in_hf_dataset(repo_id, \"ministral_8b_on_policy\", \"ministral_8b_off_policy\")\n",
    "success = rename_files_in_hf_dataset(repo_id, \"mistral_7b_on_policy\", \"mistral_7b_off_policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f56ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "repo_id = \"lasrprobegen/refusal-activations\"\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"_balanced\", \"\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"_5k\", \"_train\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"_4k\", \"_train\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"_3k\", \"_train\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"_1k\", \"_test\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"_500\", \"_test\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"_test_test\", \"_test\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"_train_train\", \"_train\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"b_t\", \"b_on_policy_t\")\n",
    "# success = rename_files_in_hf_dataset(repo_id, \"ministral-8b\", \"ministral_8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c6c4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, list_repo_files, CommitOperationCopy, CommitOperationDelete\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "def rename_folder(repo_id: str, old_folder: str, new_folder: str, confirm: bool = True):\n",
    "    \"\"\"\n",
    "    Rename a folder in a Hugging Face repo by copying its contents into a new folder\n",
    "    and deleting the old ones.\n",
    "\n",
    "    Args:\n",
    "        repo_id (str): The Hugging Face repo ID.\n",
    "        old_folder (str): The current folder name.\n",
    "        new_folder (str): The new folder name.\n",
    "        confirm (bool): Whether to ask before committing.\n",
    "    \"\"\"\n",
    "    repo_type = \"dataset\"\n",
    "    if not old_folder.endswith(\"/\"):\n",
    "        old_folder += \"/\"\n",
    "    if not new_folder.endswith(\"/\"):\n",
    "        new_folder += \"/\"\n",
    "\n",
    "    files = list_repo_files(repo_id=repo_id, repo_type=repo_type)\n",
    "\n",
    "    # Collect files under old_folder\n",
    "    files_to_move = [f for f in files if f.startswith(old_folder)]\n",
    "\n",
    "    if not files_to_move:\n",
    "        print(f\"No files found in folder '{old_folder}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(files_to_move)} files to rename from '{old_folder}' → '{new_folder}':\")\n",
    "    for old_filename in files_to_move:\n",
    "        new_filename = new_folder + old_filename[len(old_folder):]\n",
    "        print(f\"  - {old_filename} -> {new_filename}\")\n",
    "\n",
    "    if confirm:\n",
    "        response = input(f\"\\nProceed with renaming folder '{old_folder}' → '{new_folder}'? (y/N): \")\n",
    "        if response.lower() != \"y\":\n",
    "            print(\"Operation cancelled.\")\n",
    "            return\n",
    "\n",
    "    operations = []\n",
    "    for old_filename in files_to_move:\n",
    "        new_filename = new_folder + old_filename[len(old_folder):]\n",
    "        operations.append(CommitOperationCopy(src_path_in_repo=old_filename, path_in_repo=new_filename))\n",
    "        operations.append(CommitOperationDelete(path_in_repo=old_filename))\n",
    "\n",
    "    commit_info = api.create_commit(\n",
    "        repo_id=repo_id,\n",
    "        repo_type=repo_type,\n",
    "        operations=operations,\n",
    "        commit_message=f\"Rename folder '{old_folder}' → '{new_folder}'\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✓ Successfully renamed '{old_folder}' → '{new_folder}'\")\n",
    "    print(f\"Commit: {commit_info.commit_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c519e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 files to rename from 'jailbreaks/' → 'jailbreaks_old/':\n",
      "  - jailbreaks/.gitattributes -> jailbreaks_old/.gitattributes\n",
      "  - jailbreaks/llama_3b/llama_3b_incentivised_test_layer_0.pkl -> jailbreaks_old/llama_3b/llama_3b_incentivised_test_layer_0.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_incentivised_test_layer_12.pkl -> jailbreaks_old/llama_3b/llama_3b_incentivised_test_layer_12.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_incentivised_test_layer_15.pkl -> jailbreaks_old/llama_3b/llama_3b_incentivised_test_layer_15.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_incentivised_test_layer_18.pkl -> jailbreaks_old/llama_3b/llama_3b_incentivised_test_layer_18.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_incentivised_test_layer_21.pkl -> jailbreaks_old/llama_3b/llama_3b_incentivised_test_layer_21.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_incentivised_test_layer_24.pkl -> jailbreaks_old/llama_3b/llama_3b_incentivised_test_layer_24.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_incentivised_test_layer_27.pkl -> jailbreaks_old/llama_3b/llama_3b_incentivised_test_layer_27.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_incentivised_test_layer_3.pkl -> jailbreaks_old/llama_3b/llama_3b_incentivised_test_layer_3.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_incentivised_test_layer_6.pkl -> jailbreaks_old/llama_3b/llama_3b_incentivised_test_layer_6.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_incentivised_test_layer_9.pkl -> jailbreaks_old/llama_3b/llama_3b_incentivised_test_layer_9.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_on_policy_train_layer_0.pkl -> jailbreaks_old/llama_3b/llama_3b_on_policy_train_layer_0.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_on_policy_train_layer_12.pkl -> jailbreaks_old/llama_3b/llama_3b_on_policy_train_layer_12.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_on_policy_train_layer_15.pkl -> jailbreaks_old/llama_3b/llama_3b_on_policy_train_layer_15.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_on_policy_train_layer_18.pkl -> jailbreaks_old/llama_3b/llama_3b_on_policy_train_layer_18.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_on_policy_train_layer_21.pkl -> jailbreaks_old/llama_3b/llama_3b_on_policy_train_layer_21.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_on_policy_train_layer_24.pkl -> jailbreaks_old/llama_3b/llama_3b_on_policy_train_layer_24.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_on_policy_train_layer_27.pkl -> jailbreaks_old/llama_3b/llama_3b_on_policy_train_layer_27.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_on_policy_train_layer_3.pkl -> jailbreaks_old/llama_3b/llama_3b_on_policy_train_layer_3.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_on_policy_train_layer_6.pkl -> jailbreaks_old/llama_3b/llama_3b_on_policy_train_layer_6.pkl\n",
      "  - jailbreaks/llama_3b/llama_3b_on_policy_train_layer_9.pkl -> jailbreaks_old/llama_3b/llama_3b_on_policy_train_layer_9.pkl\n",
      "  - jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_0.pkl -> jailbreaks_old/llama_3b/ministral_8b_on_policy_train_layer_0.pkl\n",
      "  - jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_12.pkl -> jailbreaks_old/llama_3b/ministral_8b_on_policy_train_layer_12.pkl\n",
      "  - jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_15.pkl -> jailbreaks_old/llama_3b/ministral_8b_on_policy_train_layer_15.pkl\n",
      "  - jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_18.pkl -> jailbreaks_old/llama_3b/ministral_8b_on_policy_train_layer_18.pkl\n",
      "  - jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_21.pkl -> jailbreaks_old/llama_3b/ministral_8b_on_policy_train_layer_21.pkl\n",
      "  - jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_24.pkl -> jailbreaks_old/llama_3b/ministral_8b_on_policy_train_layer_24.pkl\n",
      "  - jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_27.pkl -> jailbreaks_old/llama_3b/ministral_8b_on_policy_train_layer_27.pkl\n",
      "  - jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_3.pkl -> jailbreaks_old/llama_3b/ministral_8b_on_policy_train_layer_3.pkl\n",
      "  - jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_6.pkl -> jailbreaks_old/llama_3b/ministral_8b_on_policy_train_layer_6.pkl\n",
      "  - jailbreaks/llama_3b/ministral_8b_on_policy_train_layer_9.pkl -> jailbreaks_old/llama_3b/ministral_8b_on_policy_train_layer_9.pkl\n",
      "  - jailbreaks/llama_3b_incentivised_test.jsonl -> jailbreaks_old/llama_3b_incentivised_test.jsonl\n",
      "  - jailbreaks/llama_3b_on_policy_train.jsonl -> jailbreaks_old/llama_3b_on_policy_train.jsonl\n",
      "  - jailbreaks/ministral_8b_on_policy_train.jsonl -> jailbreaks_old/ministral_8b_on_policy_train.jsonl\n",
      "  - jailbreaks/prompts.jsonl -> jailbreaks_old/prompts.jsonl\n",
      "\n",
      "✓ Successfully renamed 'jailbreaks/' → 'jailbreaks_old/'\n",
      "Commit: https://huggingface.co/datasets/lasrprobegen/refusal-activations/commit/4774da74ee1c2a59b3494a7689247cdf3bca144a\n"
     ]
    }
   ],
   "source": [
    "# Rename folder \"arguments/llama_3b/\" to \"arguments/llama3/\"\n",
    "rename_folder(\"lasrprobegen/refusal-activations\", \"jailbreaks\", \"jailbreaks_old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b7e4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, hf_hub_download, upload_file, list_repo_files\n",
    "import os\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "def merge_dataset_repos(\n",
    "    src_repo: str,\n",
    "    dst_repo: str,\n",
    "    dst_folder: str = \"\",\n",
    "    match: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Merge files from src_repo into dst_repo by downloading and re-uploading.\n",
    "\n",
    "    Args:\n",
    "        src_repo (str): Source dataset repo ID.\n",
    "        dst_repo (str): Destination dataset repo ID.\n",
    "        dst_folder (str): Optional subfolder inside dst_repo to upload files to.\n",
    "        match (str | None): Optional substring; only files containing this will be moved.\n",
    "    \"\"\"\n",
    "    if dst_folder and not dst_folder.endswith(\"/\"):\n",
    "        dst_folder += \"/\"\n",
    "\n",
    "    # List files in source repo\n",
    "    files = list_repo_files(repo_id=src_repo, repo_type=\"dataset\")\n",
    "\n",
    "    # Filter by match substring\n",
    "    if match is not None:\n",
    "        files = [f for f in files if match in f]\n",
    "\n",
    "    if not files:\n",
    "        print(\"No files found to merge.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(files)} files to merge from {src_repo} into {dst_repo}:\")\n",
    "\n",
    "    for f in files:\n",
    "        print(f\"  - {f}\")\n",
    "\n",
    "    proceed = input(\"\\nProceed with downloading and uploading? (y/N): \")\n",
    "    if proceed.lower() != \"y\":\n",
    "        print(\"Operation cancelled.\")\n",
    "        return\n",
    "\n",
    "    for f in files:\n",
    "        # Download file locally (temp folder)\n",
    "        local_path = hf_hub_download(repo_id=src_repo, filename=f, repo_type=\"dataset\")\n",
    "        # Determine new path in destination repo\n",
    "        new_path = f\"{dst_folder}{f}\"\n",
    "        print(f\"Uploading {f} -> {new_path} ...\")\n",
    "        upload_file(\n",
    "            path_or_fileobj=local_path,\n",
    "            path_in_repo=new_path,\n",
    "            repo_id=dst_repo,\n",
    "            repo_type=\"dataset\",\n",
    "            # overwrite=True\n",
    "        )\n",
    "\n",
    "    print(f\"\\n✓ Successfully merged {len(files)} files into {dst_repo}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e79605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 files to merge from lasrprobegen/sandbagging_multi-deception-activations into lasrprobegen/sandbagging-activations:\n",
      "  - .gitattributes\n",
      "  - llama_3b_balanced_3k.jsonl\n",
      "  - llama_3b_balanced_3k_layer_0.pkl\n",
      "  - llama_3b_balanced_3k_layer_12.pkl\n",
      "  - llama_3b_balanced_3k_layer_15.pkl\n",
      "  - llama_3b_balanced_3k_layer_18.pkl\n",
      "  - llama_3b_balanced_3k_layer_21.pkl\n",
      "  - llama_3b_balanced_3k_layer_24.pkl\n",
      "  - llama_3b_balanced_3k_layer_27.pkl\n",
      "  - llama_3b_balanced_3k_layer_3.pkl\n",
      "  - llama_3b_balanced_3k_layer_6.pkl\n",
      "  - llama_3b_balanced_3k_layer_9.pkl\n",
      "  - llama_3b_balanced_500.jsonl\n",
      "  - llama_3b_balanced_500_layer_0.pkl\n",
      "  - llama_3b_balanced_500_layer_12.pkl\n",
      "  - llama_3b_balanced_500_layer_15.pkl\n",
      "  - llama_3b_balanced_500_layer_18.pkl\n",
      "  - llama_3b_balanced_500_layer_21.pkl\n",
      "  - llama_3b_balanced_500_layer_24.pkl\n",
      "  - llama_3b_balanced_500_layer_27.pkl\n",
      "  - llama_3b_balanced_500_layer_3.pkl\n",
      "  - llama_3b_balanced_500_layer_6.pkl\n",
      "  - llama_3b_balanced_500_layer_9.pkl\n",
      "  - llama_3b_outputs_10k.jsonl\n",
      "  - llama_3b_outputs_25k.jsonl\n",
      "  - llama_3b_prompted_balanced_3k.jsonl\n",
      "  - llama_3b_prompted_balanced_3k_layer_0.pkl\n",
      "  - llama_3b_prompted_balanced_3k_layer_12.pkl\n",
      "  - llama_3b_prompted_balanced_3k_layer_15.pkl\n",
      "  - llama_3b_prompted_balanced_3k_layer_18.pkl\n",
      "  - llama_3b_prompted_balanced_3k_layer_21.pkl\n",
      "  - llama_3b_prompted_balanced_3k_layer_24.pkl\n",
      "  - llama_3b_prompted_balanced_3k_layer_27.pkl\n",
      "  - llama_3b_prompted_balanced_3k_layer_3.pkl\n",
      "  - llama_3b_prompted_balanced_3k_layer_6.pkl\n",
      "  - llama_3b_prompted_balanced_3k_layer_9.pkl\n",
      "  - llama_3b_prompted_balanced_500.jsonl\n",
      "  - llama_3b_prompted_balanced_500_layer_0.pkl\n",
      "  - llama_3b_prompted_balanced_500_layer_12.pkl\n",
      "  - llama_3b_prompted_balanced_500_layer_15.pkl\n",
      "  - llama_3b_prompted_balanced_500_layer_18.pkl\n",
      "  - llama_3b_prompted_balanced_500_layer_21.pkl\n",
      "  - llama_3b_prompted_balanced_500_layer_24.pkl\n",
      "  - llama_3b_prompted_balanced_500_layer_27.pkl\n",
      "  - llama_3b_prompted_balanced_500_layer_3.pkl\n",
      "  - llama_3b_prompted_balanced_500_layer_6.pkl\n",
      "  - llama_3b_prompted_balanced_500_layer_9.pkl\n",
      "  - llama_3b_prompted_outputs_10k.jsonl\n",
      "  - llama_3b_prompted_outputs_25k.jsonl\n",
      "  - ministral_8b_balanced_3k.jsonl\n",
      "  - ministral_8b_balanced_3k_layer_0.pkl\n",
      "  - ministral_8b_balanced_3k_layer_12.pkl\n",
      "  - ministral_8b_balanced_3k_layer_15.pkl\n",
      "  - ministral_8b_balanced_3k_layer_18.pkl\n",
      "  - ministral_8b_balanced_3k_layer_21.pkl\n",
      "  - ministral_8b_balanced_3k_layer_24.pkl\n",
      "  - ministral_8b_balanced_3k_layer_27.pkl\n",
      "  - ministral_8b_balanced_3k_layer_3.pkl\n",
      "  - ministral_8b_balanced_3k_layer_6.pkl\n",
      "  - ministral_8b_balanced_3k_layer_9.pkl\n",
      "  - ministral_8b_balanced_500.jsonl\n",
      "  - ministral_8b_balanced_500_layer_0.pkl\n",
      "  - ministral_8b_balanced_500_layer_12.pkl\n",
      "  - ministral_8b_balanced_500_layer_15.pkl\n",
      "  - ministral_8b_balanced_500_layer_18.pkl\n",
      "  - ministral_8b_balanced_500_layer_21.pkl\n",
      "  - ministral_8b_balanced_500_layer_24.pkl\n",
      "  - ministral_8b_balanced_500_layer_27.pkl\n",
      "  - ministral_8b_balanced_500_layer_3.pkl\n",
      "  - ministral_8b_balanced_500_layer_6.pkl\n",
      "  - ministral_8b_balanced_500_layer_9.pkl\n",
      "  - ministral_8b_outputs_10k.jsonl\n",
      "  - ministral_8b_outputs_25k.jsonl\n",
      "  - sandbagging_10k.jsonl\n",
      "  - sandbagging_25k.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading .gitattributes -> multichoice/.gitattributes ...\n",
      "Uploading llama_3b_balanced_3k.jsonl -> multichoice/llama_3b_balanced_3k.jsonl ...\n",
      "Uploading llama_3b_balanced_3k_layer_0.pkl -> multichoice/llama_3b_balanced_3k_layer_0.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b81477968c43baa2c8616331f2b82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97f219e4d604eae931e0efc888d2d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a6beca580848bb94a9d820317f5455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_3k_layer_12.pkl:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_3k_layer_12.pkl -> multichoice/llama_3b_balanced_3k_layer_12.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee1957e07e04f8b9966b7683d742a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a89c7d36a284a9ba92c8861134c5cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4389b8ccdbef4621853468747766fff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_3k_layer_15.pkl:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_3k_layer_15.pkl -> multichoice/llama_3b_balanced_3k_layer_15.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1839d7c15ac44d729d94e7713fa8c15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7b6582f5dc479684612d103e1967c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd054ee7f494f01842461c28091ad58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_3k_layer_18.pkl:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_3k_layer_18.pkl -> multichoice/llama_3b_balanced_3k_layer_18.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d2687c0804454cae5989fdc076a6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fd9bd5f89540f1b9c71a44e255af83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3964b437615647ed98111c2ee3983f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_3k_layer_21.pkl:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_3k_layer_21.pkl -> multichoice/llama_3b_balanced_3k_layer_21.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a920665de2847d0bc8a2fe77921dbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc5d3af0daf48b68a99dc1d85fffe59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60eb5b5af424401a93414580680f3062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_3k_layer_24.pkl:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_3k_layer_24.pkl -> multichoice/llama_3b_balanced_3k_layer_24.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a9b70cba8e4ca4b7a1c646505eaaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bcc61d02a44674b0fd3e5a05cf703a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219ca4ad2f954cdabc2be1ef29ae3bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_3k_layer_27.pkl:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_3k_layer_27.pkl -> multichoice/llama_3b_balanced_3k_layer_27.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1623b81df3b4f2c9e0b840c4fa03e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5382c9ebdf4c5b8315a1e41edc306d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a5be639e4e4d4eb54ca61f89b96fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_3k_layer_3.pkl:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_3k_layer_3.pkl -> multichoice/llama_3b_balanced_3k_layer_3.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3773bd6f1ea94942bb238c8fb194e4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba91b894f7a741f8a830047fb0056492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c91b6e3e02f4eddb8152f0da596f1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_3k_layer_6.pkl:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_3k_layer_6.pkl -> multichoice/llama_3b_balanced_3k_layer_6.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700868427d4e45bb894d584bf5cb8d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08af75769c1436b9453dbd3482b1bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b09122aa914307894e924d49e6fb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_3k_layer_9.pkl:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_3k_layer_9.pkl -> multichoice/llama_3b_balanced_3k_layer_9.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d64afdee90242adbd15feee45abb3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1900f460d249119afe58833c4389cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab94df0d3944ad2b5cca2ea558c80ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_500.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_500.jsonl -> multichoice/llama_3b_balanced_500.jsonl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9fccf2b9a348eebf3a955f69a6212f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_500_layer_0.pkl:   0%|          | 0.00/601M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading llama_3b_balanced_500_layer_0.pkl -> multichoice/llama_3b_balanced_500_layer_0.pkl ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5631f527504b401da02c9b1f361f6d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff483ab46f9847b2a33831392632f8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1a47e418d7484b9282b5005f6bebf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama_3b_balanced_500_layer_12.pkl:   0%|          | 0.00/601M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge_dataset_repos(\n",
    "    src_repo=\"lasrprobegen/sandbagging_multi-deception-activations\",\n",
    "    dst_repo=\"lasrprobegen/sandbagging-activations\",\n",
    "    dst_folder=\"multichoice/\",  # optional\n",
    "    # match=\".pkl\"                # optional filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829c5f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you're logged in to Hugging Face:\n",
      "Run: huggingface-cli login\n",
      "\n",
      "Fetching file list from repository...\n",
      "Found 0 files to delete:\n",
      "No files found containing 'off_policy'.\n"
     ]
    }
   ],
   "source": [
    "# Delete all files in the hugging face repo that contain \"on_policy\" in their name\n",
    "from huggingface_hub import HfApi, list_repo_files, CommitOperationDelete\n",
    "\n",
    "# Initialize the API\n",
    "api = HfApi()\n",
    "\n",
    "# Your dataset repository\n",
    "repo_id = \"lasrprobegen/anthropic-refusal-activations\"\n",
    "repo_type = \"dataset\"\n",
    "\n",
    "def delete_off_policy_files():\n",
    "    \"\"\"\n",
    "    Delete all files that contain 'on_policy' in their name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # List all files in the repository\n",
    "        print(\"Fetching file list from repository...\")\n",
    "        files = list_repo_files(repo_id=repo_id, repo_type=repo_type)\n",
    "        \n",
    "        # Find files containing \"off_policy\"\n",
    "        files_to_delete = [f for f in files if \"on_policy\" in f]\n",
    "        \n",
    "        print(f\"Found {len(files_to_delete)} files to delete:\")\n",
    "        for file in files_to_delete:\n",
    "            print(f\"  - {file}\")\n",
    "        \n",
    "        if not files_to_delete:\n",
    "            print(\"No files found containing 'off_policy'.\")\n",
    "            return\n",
    "        \n",
    "        # Confirm before proceeding\n",
    "        response = input(f\"\\nProceed with deleting {len(files_to_delete)} files? (y/N): \")\n",
    "        if response.lower() != 'y':\n",
    "            print(\"Operation cancelled.\")\n",
    "            return\n",
    "        \n",
    "        # Prepare commit operations\n",
    "        operations = [CommitOperationDelete(path_in_repo=f) for f in files_to_delete]\n",
    "        \n",
    "        print(f\"Creating commit with {len(operations)} delete operations...\")\n",
    "        \n",
    "        # Execute all operations in a single commit\n",
    "        commit_info = api.create_commit(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type,\n",
    "            operations=operations,\n",
    "            commit_message=f\"Delete {len(files_to_delete)} files containing 'off_policy'\"\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Successfully deleted files!\")\n",
    "        print(f\"Commit: {commit_info.commit_url}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"Make sure you have:\")\n",
    "        print(\"1. Installed huggingface_hub: pip install huggingface_hub\")\n",
    "        print(\"2. Logged in: huggingface-cli login\")\n",
    "        print(\"3. Write access to the repository\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Make sure you're logged in to Hugging Face:\")\n",
    "    print(\"Run: huggingface-cli login\")\n",
    "    print()\n",
    "    \n",
    "    delete_off_policy_files()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
