{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1a462d",
   "metadata": {},
   "source": [
    "# Summary Plots Barcharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631a5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "# If getting 'Could not find project LASR_probe_gen' get key from https://wandb.ai/authorize and paste below\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "# os.environ[\"WANDB_API_KEY\"] = \"\"\n",
    "import wandb\n",
    "wandb_token = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(key=wandb_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f79565",
   "metadata": {},
   "source": [
    "## Behaviour Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.behaviour_bar_plot import plot_behaviour_barchart\n",
    "from probe_gen.config import BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL, BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL_DECEPTION\n",
    "\n",
    "# Define graph type\n",
    "train_OOD = [False, True][0] # means test set wont match train set\n",
    "test_incentivised = [False, True][0] # means we test against incentivised data\n",
    "\n",
    "# Set probe type and activation model and keep all other parameters as initial experiments\n",
    "probe_type = [\"mean\", \"attention_torch\"][0]\n",
    "activations_model = [\"llama_3b\", \"ministral_8b\", \"gemma_27b\"][0]\n",
    "\n",
    "done_experiments = BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL\n",
    "if test_incentivised:\n",
    "    done_experiments.update(BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL_DECEPTION)\n",
    "# Get experiments into format\n",
    "# [probe_type, behaviour, [ID datasource, OOD datasource], activations_model, [ID off_policy_model, OOD off_policy_model]]\n",
    "train_setup = []\n",
    "for behaviour in list(done_experiments.keys()):\n",
    "    ds = list(done_experiments[behaviour].keys())[1:]\n",
    "    off_mods = [done_experiments[behaviour][ds[0]][activations_model], done_experiments[behaviour][ds[1]][activations_model]]\n",
    "    train_setup.append([probe_type, behaviour, [ds[0], ds[1]], activations_model, [off_mods[0], off_mods[1]]])\n",
    "    if done_experiments[behaviour][\"test_both\"]:\n",
    "        train_setup.append([probe_type, behaviour, [ds[1], ds[0]], activations_model, [off_mods[1], off_mods[0]]])\n",
    "\n",
    "plot_behaviour_barchart(\n",
    "    train_setup=train_setup,\n",
    "    train_OOD=train_OOD,\n",
    "    test_incentivised=test_incentivised,\n",
    "    add_mean_summary=False,\n",
    "    save_path=\"linear_id_onpolicy.pdf\",\n",
    "    # save_path=\"linear_ood_onpolicy.pdf\",\n",
    "    # save_path=\"attention_id_onpolicy.pdf\",\n",
    "    # save_path=\"attention_ood_onpolicy.pdf\",\n",
    "    legend_loc=\"upper right\",\n",
    "    extra_whitespace=2,    \n",
    "    # save_path=\"linear_id_incentivised.pdf\",\n",
    "    # # save_path=\"attention_id_incentivised.pdf\",\n",
    "    # legend_loc=\"lower left\",\n",
    "    # extra_whitespace=0,\n",
    "    probe_type=probe_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da5d42",
   "metadata": {},
   "source": [
    "## Behaviour Plots (Same-Test-Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb50cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.behaviour_bar_plot import plot_behaviour_barchart_same_test_train\n",
    "from probe_gen.config import BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL, BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL_DECEPTION\n",
    "\n",
    "# Define graph type\n",
    "train_OOD = [False, True][0] # means test set wont match train set\n",
    "include_deception = [False, True][0]\n",
    "\n",
    "# Set probe type and activation model and keep all other parameters as initial experiments\n",
    "probe_type = [\"mean\", \"attention_torch\"][0]\n",
    "activations_model = [\"llama_3b\", \"ministral_8b\", \"gemma_27b\"][0] # currently the only option\n",
    "\n",
    "done_experiments = BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL\n",
    "if include_deception:\n",
    "    done_experiments.update(BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL_DECEPTION)\n",
    "    \n",
    "# Get experiments into format\n",
    "# [probe_type, behaviour, [ID datasource, OOD datasource], activations_model, [ID off_policy_model, OOD off_policy_model]]\n",
    "train_setup = []\n",
    "for behaviour in list(done_experiments.keys()):\n",
    "    ds = list(done_experiments[behaviour].keys())[1:]\n",
    "    off_mods = [done_experiments[behaviour][ds[0]][activations_model], done_experiments[behaviour][ds[1]][activations_model]]\n",
    "    train_setup.append([probe_type, behaviour, [ds[0], ds[1]], activations_model, [off_mods[0], off_mods[1]]])\n",
    "    if done_experiments[behaviour][\"test_both\"]:\n",
    "        train_setup.append([probe_type, behaviour, [ds[1], ds[0]], activations_model, [off_mods[1], off_mods[0]]])\n",
    "\n",
    "plot_behaviour_barchart_same_test_train(\n",
    "    train_setup=train_setup,\n",
    "    train_OOD=train_OOD,\n",
    "    add_mean_summary=False,\n",
    "    save_path=\"linear_baseline.pdf\",\n",
    "    # save_path=\"attention_baseline.pdf\",\n",
    "    legend_loc=\"lower left\" if include_deception else \"upper right\",\n",
    "    extra_whitespace=0 if include_deception else 2,\n",
    "    probe_type=probe_type,\n",
    "    do_seperator_line=include_deception,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285048d",
   "metadata": {},
   "source": [
    "## Behaviour Plots (Deception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c735825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.behaviour_bar_plot import plot_behaviour_barchart\n",
    "from probe_gen.config import BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL_DECEPTION\n",
    "\n",
    "# Define graph type\n",
    "train_OOD = [False, True][0] # means test set wont match train set\n",
    "\n",
    "# Set probe type and activation model and keep all other parameters as initial experiments\n",
    "probe_type = [\"mean\", \"attention_torch\"][0]\n",
    "activations_model = [\"llama_3b\", \"other\"][0]\n",
    "\n",
    "done_experiments = BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL_DECEPTION\n",
    "model_map = {\n",
    "    \"deception\": {\n",
    "        \"roleplaying\": \"mistral_7b\",\n",
    "        \"trading\": \"mixtral\",},\n",
    "    \"sandbagging\": {\n",
    "        \"wmd\": \"mistral_7b\",\n",
    "        \"multichoice\": \"ministral_8b\"},\n",
    "}\n",
    "\n",
    "# Get experiments into format\n",
    "# [probe_type, behaviour, [ID datasource, OOD datasource], activations_model, [ID off_policy_model, OOD off_policy_model]]\n",
    "if activations_model == \"llama_3b\":\n",
    "    train_setup = []\n",
    "    for behaviour in list(done_experiments.keys()):  \n",
    "        ds = list(done_experiments[behaviour].keys())[1:]\n",
    "        off_mods = [done_experiments[behaviour][ds[0]][activations_model], done_experiments[behaviour][ds[1]][activations_model]]\n",
    "        train_setup.append([probe_type, behaviour, [ds[0], ds[1]], activations_model, [off_mods[0], off_mods[1]]])\n",
    "        train_setup.append([probe_type, behaviour, [ds[1], ds[0]], activations_model, [off_mods[1], off_mods[0]]])\n",
    "else:\n",
    "    train_setup = []\n",
    "    for behaviour in list(done_experiments.keys()):  \n",
    "        ds = list(done_experiments[behaviour].keys())[1:]\n",
    "        activations_model = model_map[behaviour][ds[0]]\n",
    "        off_mods = [done_experiments[behaviour][ds[0]][activations_model], None]\n",
    "        train_setup.append([probe_type, behaviour, [ds[0], ds[1]], activations_model, [off_mods[0], off_mods[1]]])\n",
    "\n",
    "        activations_model = model_map[behaviour][ds[1]]\n",
    "        off_mods = [done_experiments[behaviour][ds[1]][activations_model], None]\n",
    "        train_setup.append([probe_type, behaviour, [ds[1], ds[0]], activations_model, [off_mods[0], off_mods[1]]])\n",
    "\n",
    "if train_OOD:\n",
    "    title=f\"{'Linear' if probe_type == 'mean' else 'Attention'} Probes Evaluated Against Diff.-Domain On-Policy Incentivised\"\n",
    "else:\n",
    "    title=f\"{'Linear' if probe_type == 'mean' else 'Attention'} Probes Evaluated Against On-Policy Incentivised\"\n",
    "\n",
    "plot_behaviour_barchart(\n",
    "    train_setup=train_setup,\n",
    "    train_OOD=train_OOD,\n",
    "    title=title,\n",
    "    figsize=(7, 3), \n",
    "    test_incentivised=True,\n",
    "    add_mean_summary=False,\n",
    "    save_path=\"linear_id_deception.pdf\",\n",
    "    # save_path=\"linear_ood_deception.pdf\",\n",
    "    # save_path=\"attention_id_deception.pdf\",\n",
    "    # save_path=\"attention_ood_deception.pdf\",\n",
    "    legend_loc=\"upper right\",\n",
    "    extra_whitespace=2,    \n",
    "    probe_type=probe_type,\n",
    "    do_seperator_line=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7526fb5",
   "metadata": {},
   "source": [
    "## Summary Plots (Dots and Lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97aed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.behaviour_bar_plot import plot_mean_summary_dotchart\n",
    "from probe_gen.config import BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL, BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL_DECEPTION\n",
    "\n",
    "# Define graph type\n",
    "test_incentivised = [False, True][0] # means we test against incentivised data\n",
    "\n",
    "# Set probe type and activation model and keep all other parameters as initial experiments\n",
    "probe_type = [\"mean\", \"attention_torch\"][0]\n",
    "activations_model = [\"llama_3b\", \"ministral_8b\", \"gemma_27b\"][0] # currently the only option\n",
    "\n",
    "done_experiments = BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL\n",
    "if test_incentivised:\n",
    "    done_experiments.update(BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL_DECEPTION)\n",
    "# Get experiments into format\n",
    "# [probe_type, behaviour, [ID datasource, OOD datasource], activations_model, [ID off_policy_model, OOD off_policy_model]]\n",
    "train_setup = []\n",
    "for behaviour in list(done_experiments.keys()):\n",
    "    ds = list(done_experiments[behaviour].keys())[1:]\n",
    "    off_mods = [done_experiments[behaviour][ds[0]][activations_model], done_experiments[behaviour][ds[1]][activations_model]]\n",
    "    train_setup.append([probe_type, behaviour, [ds[0], ds[1]], activations_model, [off_mods[0], off_mods[1]]])\n",
    "    if done_experiments[behaviour][\"test_both\"]:\n",
    "        train_setup.append([probe_type, behaviour, [ds[1], ds[0]], activations_model, [off_mods[1], off_mods[0]]])\n",
    "\n",
    "plot_mean_summary_dotchart(\n",
    "    train_setup=train_setup,\n",
    "    test_incentivised=test_incentivised,\n",
    "    save_path=\"linear_id_vs_ood_onpolicy2.pdf\",\n",
    "    # save_path=\"attention_id_vs_ood_onpolicy2.pdf\",\n",
    "    legend_loc=\"upper right\",\n",
    "    # legend_loc=\"lower left\",\n",
    "    extra_whitespace=0,\n",
    "    probe_type=probe_type,\n",
    "    draw_blobs=True, # Can be set to False to see just dots\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e52813",
   "metadata": {},
   "source": [
    "## Summary Plots (Mean Bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.behaviour_bar_plot import plot_mean_summary_barchart\n",
    "from probe_gen.config import BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL, BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL_DECEPTION\n",
    "\n",
    "# Define graph type\n",
    "test_incentivised = [False, True][0] # means we test against incentivised data\n",
    "\n",
    "# Set probe type and activation model and keep all other parameters as initial experiments\n",
    "probe_type = [\"mean\", \"attention_torch\"][0]\n",
    "activations_model = [\"llama_3b\", \"ministral_8b\", \"gemma_27b\"][0] # currently the only option\n",
    "\n",
    "done_experiments = BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL\n",
    "if test_incentivised:\n",
    "    done_experiments.update(BEHAVIOUR_DATASOURCE_ACTMODEL_OFFPOLICYMODEL_DECEPTION)\n",
    "# Get experiments into format\n",
    "# [probe_type, behaviour, [ID datasource, OOD datasource], activations_model, [ID off_policy_model, OOD off_policy_model]]\n",
    "train_setup = []\n",
    "for behaviour in list(done_experiments.keys()):\n",
    "    ds = list(done_experiments[behaviour].keys())[1:]\n",
    "    off_mods = [done_experiments[behaviour][ds[0]][activations_model], done_experiments[behaviour][ds[1]][activations_model]]\n",
    "    train_setup.append([probe_type, behaviour, [ds[0], ds[1]], activations_model, [off_mods[0], off_mods[1]]])\n",
    "    if done_experiments[behaviour][\"test_both\"]:\n",
    "        train_setup.append([probe_type, behaviour, [ds[1], ds[0]], activations_model, [off_mods[1], off_mods[0]]])\n",
    "\n",
    "plot_mean_summary_barchart(\n",
    "    train_setup=train_setup,\n",
    "    test_incentivised=test_incentivised,\n",
    "    # save_path=\"linear_id_vs_ood_onpolicy.pdf\",\n",
    "    # save_path=\"attention_id_vs_ood_onpolicy.pdf\",\n",
    "    legend_loc=\"upper right\",\n",
    "    # legend_loc=\"lower left\",\n",
    "    extra_whitespace=0,\n",
    "    probe_type=probe_type,\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
